{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Numba first steps\n",
        "\n",
        "François-David Collin (CNRS, IMAG, Paul-Valéry Montpellier 3\n",
        "University)  \n",
        "Wednesday, August 27, 2025\n",
        "\n",
        "## Rewind on sequence searching\n",
        "\n",
        "Make a proper function of the sequence searching Application from\n",
        "`0_Numpy workout.ipynb`. Test it.\n",
        "\n",
        "``` python\n",
        "def search_sequence_numpy(data,seq):\n",
        "    ...\n",
        "```"
      ],
      "id": "976e73cc-a078-495b-b0e9-333ccbbc9384"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "data = np.array([1,3,2,3,5,9,2,3,5,1,0],dtype=np.uint8)\n",
        "sequence = np.array([3,5],dtype=np.uint8)"
      ],
      "id": "bc1ad05a"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "tags": [
          "solution"
        ]
      },
      "outputs": [],
      "source": [
        "def search_sequence_numpy(data,seq):\n",
        "    seq_ind = np.arange(seq.size)\n",
        "    cor_size = data.size-seq.size+1\n",
        "    data_ind = np.arange(cor_size).reshape((cor_size,1))\n",
        "    \n",
        "    return np.nonzero(np.all(data[data_ind + seq_ind] == seq,1))[0]"
      ],
      "id": "cdad6894"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "array([3, 7])"
            ]
          }
        }
      ],
      "source": [
        "search_sequence_numpy(data,sequence)"
      ],
      "id": "a1b08b45"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Numba migration\n",
        "\n",
        "We want to “unroll” numpy code in double nested loop, simply walking\n",
        "`data` and `sequence` and put results in an accumulator, one element at\n",
        "a time. Write the missing line.\n",
        "\n",
        "``` python\n",
        "import numba\n",
        "\n",
        "@numba.jit(nopython=True)\n",
        "def search_sequence_numba(data,seq):\n",
        "    cor_size = data.size-seq.size+1\n",
        "    \n",
        "    matches = np.ones(cor_size,dtype=np.uint8)\n",
        "    \n",
        "    for i in range(cor_size): # walking on data\n",
        "        for j in range(seq.size): # walking on sequence\n",
        "            ...\n",
        "            \n",
        "    return np.nonzero(matches)[0]\n",
        "\n",
        "search_sequence_numba(data,sequence)\n",
        "```"
      ],
      "id": "3bf630aa-7e57-46f8-b93a-dbfc489d5658"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "tags": [
          "solution"
        ]
      },
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "array([3, 7])"
            ]
          }
        }
      ],
      "source": [
        "import numba\n",
        "\n",
        "@numba.jit(nopython=True)\n",
        "def search_sequence_numba(data,seq):\n",
        "    cor_size = data.size-seq.size+1\n",
        "    \n",
        "    matches = np.ones(cor_size,dtype=np.uint8)\n",
        "    \n",
        "    for i in range(cor_size): # walking on data\n",
        "        for j in range(seq.size): # walking on sequence\n",
        "            if data[i+j] != seq[j]:\n",
        "                matches[i] = 0      \n",
        "                break\n",
        "            \n",
        "    return np.nonzero(matches)[0]\n",
        " \n",
        "search_sequence_numba(data,sequence)"
      ],
      "id": "806c1b12"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Blow it up\n",
        "\n",
        "Generate 10000 of random digits (the data) a sequence of 3 digits, and\n",
        "benchmark both versions (numpy and numba) on it. Compare and comment."
      ],
      "id": "8c68de2d-3841-400f-9672-4cb95a098b94"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "tags": [
          "solution"
        ]
      },
      "outputs": [],
      "source": [
        "data_rand = np.random.randint(10,size=int(1e6))\n",
        "sequence_rand = np.random.randint(10,size=3)"
      ],
      "id": "01dcc4e1"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "array([   708,   4010,   4795, ..., 997370, 997401, 998691], shape=(1019,))"
            ]
          }
        }
      ],
      "source": [
        "search_sequence_numpy(data_rand,sequence_rand)"
      ],
      "id": "6f0f339f"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "tags": [
          "solution"
        ]
      },
      "outputs": [],
      "source": [
        "np.testing.assert_array_equal(search_sequence_numpy(data_rand,sequence_rand),\n",
        "                              search_sequence_numba(data_rand,sequence_rand))"
      ],
      "id": "6c7cff1d"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "tags": [
          "solution"
        ]
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14.1 ms ± 149 μs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
            "1.23 ms ± 15.6 μs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
            "Numba speedup over Numpy : 11.4"
          ]
        }
      ],
      "source": [
        "numpy_time = %timeit -o -r 7 -n 10 search_sequence_numpy(data_rand,sequence_rand)\n",
        "numba_time = %timeit -o -r 7 -n 10 search_sequence_numba(data_rand,sequence_rand)\n",
        "print(\"Numba speedup over Numpy : {:.1f}\".format(numpy_time.average/numba_time.average))"
      ],
      "id": "53100e5b"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "benchmarks = pd.DataFrame(\n",
        "    {\"data size\":int(1e6),\n",
        "     \"version\":\"numpy\",\n",
        "     \"timing\":numpy_time.average},\n",
        "    index=[0])\n",
        "benchmarks = pd.concat(\n",
        "    [benchmarks,\n",
        "     pd.Series(\n",
        "         {\"data size\":int(1e6),\n",
        "          \"version\":\"numba\",\n",
        "          \"timing\":numba_time.average\n",
        "         }).to_frame().T],ignore_index=True)"
      ],
      "id": "1eaa01d9"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## And now… parallelize\n",
        "\n",
        "Question : is pattern matching like we just did an “embarrassingly\n",
        "parallel” problem ? Explain.\n",
        "\n",
        "It shouldn’t be : if we partition the data in chunks, the pattern\n",
        "matching will miss any match occuring between two consecutive chunks.\n",
        "\n",
        "Numba got a powerful (multi-threaded) parallelization feature, one\n",
        "just needs to : 1. add `parallel=True` in the decorator call 2. replace\n",
        "python `range` used for looping with numba’s `prange`.\n",
        "\n",
        "With a spetial attention to where you could put parallelization\n",
        "directive with prange (remember the “Concepts” course). Test and\n",
        "benchmark, give the speedup and comment.\n",
        "\n",
        "Why there si no *race condition* there ? (Tip : consider concurrent\n",
        "access in multi-threading, and look closely in the loop to read/store to\n",
        "the data)."
      ],
      "id": "ddd8908e-2a41-4744-b2c0-38d44d7331b2"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "tags": [
          "solution"
        ]
      },
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "array([3, 7])"
            ]
          }
        }
      ],
      "source": [
        "import numba\n",
        "\n",
        "@numba.jit(nopython=True,parallel=True)\n",
        "def search_sequence_numba_parallel(data,seq):\n",
        "    cor_size = data.size-seq.size+1\n",
        "    \n",
        "    matches = np.ones(cor_size,dtype=np.uint8)\n",
        "\n",
        "    for i in numba.prange(cor_size): # walking on data\n",
        "        for j in range(seq.size): # walking on sequence\n",
        "            if data[i+j] != seq[j]:\n",
        "                matches[i] = 0      \n",
        "                break\n",
        "                \n",
        "    return np.nonzero(matches)[0]\n",
        "\n",
        "search_sequence_numba_parallel(data,sequence)"
      ],
      "id": "6a7d10e3"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "tags": [
          "solution"
        ]
      },
      "outputs": [],
      "source": [
        "np.testing.assert_array_equal(search_sequence_numpy(data_rand,sequence_rand),\n",
        "                              search_sequence_numba_parallel(data_rand,sequence_rand))"
      ],
      "id": "510cdb79"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "tags": [
          "solution"
        ]
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "721 μs ± 34.3 μs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
            "Numba parallel speedup over numba : 1.7"
          ]
        }
      ],
      "source": [
        "numba_parallel_time = %timeit -r 7 -n 10  -o search_sequence_numba_parallel(data_rand,sequence_rand)\n",
        "print(\"Numba parallel speedup over numba : {:.1f}\".format(numba_time.average/numba_parallel_time.average))\n",
        "\n",
        "benchmarks = pd.concat(\n",
        "    [benchmarks,\n",
        "     pd.Series(\n",
        "         {\"data size\":int(1e6),\n",
        "          \"version\":\"numba parallel\",\n",
        "          \"timing\":numba_parallel_time.average\n",
        "         }).to_frame().T],ignore_index=True)"
      ],
      "id": "11b1b682"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Over 2~3 speedup over the non-parallel version is a sensible one on a\n",
        "the current 4-core CPU.\n",
        "\n",
        "There is no race condition because all data/sequence access are only\n",
        "read and the only assignment is on `matches[i]` which depends only\n",
        "on itself and data/sequence read. As a `prange` on `matches` index gives\n",
        "exclusive partitions per thread, it is guaranted that a thread will\n",
        "never access `matches` from other thread partitions.\n",
        "\n",
        "# Multi-processing vs Multi-threading\n",
        "\n",
        "Is this type of parallelization “trick” also possible as is with\n",
        "multi-processing ?\n",
        "\n",
        "Has multi-threading any advantage over multiprocessing in this context ?\n",
        "\n",
        "Let’s look into it.\n",
        "\n",
        "Make a modified `search_sequence_numba2` which takes a index subrange of\n",
        "the `matches` array and return the matches only on this range. Test it\n",
        "on the original `data` and `sequence` with two chunks.\n",
        "\n",
        "``` python\n",
        "@numba.jit(nopython=True)\n",
        "def search_sequence_numba2(data,seq,chunk):\n",
        "    matches = ...\n",
        "    \n",
        "    for i,ic in enumerate(chunk): # walking on data\n",
        "        for j in range(seq.size): # walking on sequence\n",
        "            ...\n",
        "            \n",
        "    return np.nonzero(matches)[0]+chunk[0]\n",
        "```"
      ],
      "id": "8dd2152e-fc19-4ec9-8d67-b83ea06f2d74"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "tags": [
          "solution"
        ]
      },
      "outputs": [],
      "source": [
        "@numba.jit(nopython=True)\n",
        "def search_sequence_numba2(data,seq,chunk):\n",
        "    matches = np.ones(chunk.size,dtype=np.uint8)\n",
        "    \n",
        "    for i,ic in enumerate(chunk): # walking on data\n",
        "        for j in range(seq.size): # walking on sequence\n",
        "            if data[ic+j] != seq[j]:\n",
        "                matches[i] = 0      \n",
        "                break\n",
        "            \n",
        "    return np.nonzero(matches)[0]+chunk[0]"
      ],
      "id": "ff63f4ce"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "tags": [
          "solution"
        ]
      },
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "[array([3]), array([7])]"
            ]
          }
        }
      ],
      "source": [
        "[search_sequence_numba2(data,sequence,np.arange(0,5)),\n",
        "             search_sequence_numba2(data,sequence,np.arange(5,12))]"
      ],
      "id": "15e52d7d"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "tags": [
          "solution"
        ]
      },
      "outputs": [],
      "source": [
        "rand_cor_size = data_rand.size-sequence_rand.size+1\n",
        "np.testing.assert_array_equal(search_sequence_numpy(data_rand,sequence_rand),\n",
        "                              search_sequence_numba2(data_rand,sequence_rand,\n",
        "                                                     np.arange(rand_cor_size)))"
      ],
      "id": "f487097a"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Recall the chunks function generator"
      ],
      "id": "1ee5dbfd-7b3f-4a2c-92e2-2c74f9c1d010"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "def chunks(lst, n):\n",
        "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
        "    for i in range(0, len(lst), n):\n",
        "        yield lst[i:i + n]"
      ],
      "id": "85e2331d"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now make the multiprocessing version, test it. Benchmark it and give the\n",
        "speedup over the numba parallel version.\n",
        "\n",
        "Do it again but this time for a random data with 10 millions of digits.\n",
        "\n",
        "``` python\n",
        "import multiprocessing\n",
        "from itertools import chain\n",
        "\n",
        "def search_sequence_multiprocessing(data,seq,ncores):\n",
        "    cor_size = data.size-seq.size+1\n",
        "    \n",
        "    ...\n",
        "```"
      ],
      "id": "9999c383-11a5-4317-ae3e-bf38733517f6"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "tags": [
          "solution"
        ]
      },
      "outputs": [],
      "source": [
        "import multiprocessing\n",
        "from itertools import chain\n",
        "\n",
        "def search_sequence_multiprocessing(data,seq,ncores):\n",
        "    cor_size = data.size-seq.size+1\n",
        "    \n",
        "    mapargs = [(data,seq,chunk) for chunk in chunks(np.arange(cor_size),int(cor_size/ncores))]\n",
        "    with multiprocessing.Pool(ncores) as p:\n",
        "        res = p.starmap(search_sequence_numba2,mapargs)\n",
        "    matches_index = list(chain(*res))\n",
        "    return matches_index\n",
        "\n",
        "np.testing.assert_array_equal(search_sequence_numpy(data_rand,sequence_rand),\n",
        "                              search_sequence_multiprocessing(data_rand,sequence_rand,8))"
      ],
      "id": "5e096068"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "tags": [
          "solution"
        ]
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "431 ms ± 2.01 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
            "Numba parallel speedup over multiprocessing : 597.7"
          ]
        }
      ],
      "source": [
        "multiprocessing_numba_time = %timeit -r 7 -n 10 -o search_sequence_multiprocessing(data_rand,sequence_rand,8)\n",
        "print(\"Numba parallel speedup over multiprocessing : {:.1f}\".format(multiprocessing_numba_time.average/numba_parallel_time.average))\n",
        "\n",
        "benchmarks = pd.concat(\n",
        "    [benchmarks,\n",
        "     pd.Series(\n",
        "         {\"data size\":int(1e6),\n",
        "          \"version\":\"multiprocessing numba\",\n",
        "          \"timing\":multiprocessing_numba_time.average\n",
        "         }).to_frame().T],ignore_index=True)"
      ],
      "id": "9840127b"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "tags": [
          "solution"
        ]
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "165 ms ± 1.82 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
            "12.9 ms ± 40.6 μs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
            "Numba speedup over Numpy : 12.8\n",
            "5.5 ms ± 58.9 μs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
            "Numba parallel speedup over numba : 2.4\n",
            "1.11 s ± 8.5 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
            "Numba parallel speedup over multiprocessing : 201.6"
          ]
        }
      ],
      "source": [
        "data_rand = np.random.randint(10,size=int(1e7))\n",
        "sequence_rand = np.random.randint(10,size=3)\n",
        "\n",
        "numpy10M_time = %timeit -o -r 7 -n 10 search_sequence_numpy(data_rand,sequence_rand)\n",
        "numba10M_time = %timeit -o -r 7 -n 10 search_sequence_numba(data_rand,sequence_rand)\n",
        "print(\"Numba speedup over Numpy : {:.1f}\".format(numpy10M_time.average/numba10M_time.average))\n",
        "numba_parallel10M_time = %timeit -r 7 -n 10 -o search_sequence_numba_parallel(data_rand,sequence_rand)\n",
        "print(\"Numba parallel speedup over numba : {:.1f}\".format(numba10M_time.average/numba_parallel10M_time.average))\n",
        "multiprocessing_numba10M_time = %timeit -r 7 -n 10 -o search_sequence_multiprocessing(data_rand,sequence_rand,8)\n",
        "print(\"Numba parallel speedup over multiprocessing : {:.1f}\".format(multiprocessing_numba10M_time.average/numba_parallel10M_time.average))"
      ],
      "id": "9f318861"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "benchmarks = pd.concat(\n",
        "    [benchmarks,\n",
        "     pd.DataFrame([\n",
        "         {\"data size\":int(1e7),\"version\":\"numpy\",\"timing\":numpy10M_time.average},\n",
        "         {\"data size\":int(1e7),\"version\":\"numba\",\"timing\":numba10M_time.average},\n",
        "         {\"data size\":int(1e7),\"version\":\"numba parallel\",\"timing\":numba_parallel10M_time.average},\n",
        "         {\"data size\":int(1e7),\"version\":\"multiprocessing numba\",\"timing\":multiprocessing_numba10M_time.average}\n",
        "     ])],\n",
        "     ignore_index=True)"
      ],
      "id": "6e04d34a"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Market it with a chart\n",
        "\n",
        "Make a bar chart with all versions timings, taking the numpy version as\n",
        "reference, and both (1e6, 1e7) runs of the data."
      ],
      "id": "eeb5c341-b3ef-4249-abc7-a55f86e7d27a"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "tags": [
          "solution"
        ]
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/var/folders/p0/pqx517ld19nf9ybmf7rbv4bc0000gn/T/ipykernel_74176/2176122905.py:6: FutureWarning:\n",
            "\n",
            "DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n"
          ]
        },
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        </script>\n",
              "        <script type=\"module\">import \"https://cdn.plot.ly/plotly-3.1.0.min\"</script>\n",
              "        "
            ]
          }
        },
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/html": [
              "<div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-3.1.0.min.js\" integrity=\"sha256-Ei4740bWZhaUTQuD6q9yQlgVCMPBz6CZWhevDYPv93A=\" crossorigin=\"anonymous\"></script>                <div id=\"7eae1d1a-9f18-4e00-82da-766851236e46\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                window.PLOTLYENV=window.PLOTLYENV || {};                                if (document.getElementById(\"7eae1d1a-9f18-4e00-82da-766851236e46\")) {                    Plotly.newPlot(                        \"7eae1d1a-9f18-4e00-82da-766851236e46\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"data size=1000000\\u003cbr\\u003eversion=%{x}\\u003cbr\\u003espeedup over numpy=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"1000000\",\"marker\":{\"color\":\"#636efa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"1000000\",\"offsetgroup\":\"1000000\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[\"numba\",\"numba parallel\",\"multiprocessing numba\"],\"xaxis\":\"x\",\"y\":[11.449340074272211,19.564846199946803,0.03273222190583966],\"yaxis\":\"y\",\"type\":\"bar\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"data size=10000000\\u003cbr\\u003eversion=%{x}\\u003cbr\\u003espeedup over numpy=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"10000000\",\"marker\":{\"color\":\"#EF553B\",\"pattern\":{\"shape\":\"\"}},\"name\":\"10000000\",\"offsetgroup\":\"10000000\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[\"numba\",\"numba parallel\",\"multiprocessing numba\"],\"xaxis\":\"x\",\"y\":[12.752524763175732,30.019476627181525,0.14890715278855385],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermap\":[{\"type\":\"scattermap\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"},\"margin\":{\"b\":0,\"l\":0,\"r\":0,\"t\":30}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"version\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"speedup over numpy\"}},\"legend\":{\"title\":{\"text\":\"data size\"},\"tracegroupgap\":0},\"barmode\":\"group\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('7eae1d1a-9f18-4e00-82da-766851236e46');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };            </script>        </div>"
            ]
          }
        }
      ],
      "source": [
        "import plotly.express as px\n",
        "\n",
        "# pandas kata 😀\n",
        "speedups = benchmarks\\\n",
        "            .groupby(\"data size\")\\\n",
        "            .apply(lambda x: x[x[\"version\"] == \"numpy\"][\"timing\"].values[0]/x[\"timing\"])\\\n",
        "            .to_frame()\\\n",
        "            .droplevel(\"data size\")\\\n",
        "            .rename(columns={\"timing\":\"speedup over numpy\"})\n",
        "to_plot = pd.concat([benchmarks,speedups],axis=1)\n",
        "to_plot = to_plot[to_plot[\"version\"] != \"numpy\"]\n",
        "\n",
        "px.bar(to_plot,barmode='group',x=\"version\",y=\"speedup over numpy\",color=\"data size\")"
      ],
      "id": "60ec40c1"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "path": "/Users/fradav/Documents/Dev/Python/Cours-programmation-MIASHS-2025/.venv/share/jupyter/kernels/python3"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": "3"
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  }
}