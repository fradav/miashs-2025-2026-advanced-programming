{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# AI Agent\n",
        "\n",
        "Taking the bull by the horns\n",
        "\n",
        "François-David Collin (CNRS, IMAG, Paul-Valéry Montpellier 3\n",
        "University)  \n",
        "Wednesday, August 27, 2025\n",
        "\n",
        "For this practical work, you need the following python packages:\n",
        "\n",
        "-   `openai`\n",
        "-   `python-dotenv`\n",
        "-   `faiss-cpu`\n",
        "-   `numpy`\n",
        "\n",
        "# Hello World\n",
        "\n",
        "Make work the example of the course.\n",
        "\n",
        "``` python\n",
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "chat_response = client.chat.completions.create(\n",
        "    model= \"gpt-4o\",\n",
        "    messages = [\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"What is the best French cheese?\",\n",
        "        },\n",
        "    ]\n",
        ")\n",
        "print(chat_response.choices[0].message.content)\n",
        "```\n",
        "\n",
        "Look at the documentation of the `OpenAI()` constructor in order to take\n",
        "your own model. Modify the model name accordingly.\n",
        "\n",
        "> **Important**\n",
        ">\n",
        "> **Never, ever** put your API key in the code. Use environment\n",
        "> variables instead. For example, use python `dotenv` to load the API\n",
        "> key from a `.env` file.\n",
        "\n",
        "> **Tip**\n",
        ">\n",
        "> The openai compatible endpoint for mistral.ai is\n",
        "> `https://api.mistral.ai/v1`. `mistral-small-latest` as the model\n",
        "> should be sufficient.\n",
        "\n",
        "> **Tip**\n",
        ">\n",
        "> If you have locally installed llm with ollama/lmstudio for example,\n",
        "> don’t hesitate to adapt the code to use your local model.\n",
        "\n",
        "# Build a RAG Agent\n",
        "\n",
        "## Split the document in chunks\n",
        "\n",
        "Get the alice.txt and split it in 2048 characters.\n",
        "\n",
        "## Encode the chunks\n",
        "\n",
        "A simple function to get an embedding is:"
      ],
      "id": "85887b1e-7281-42dc-b45e-6df76317add7"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "from time import sleep\n",
        "\n",
        "def get_text_embedding(input):\n",
        "    sleep(1) # Rate-limiting\n",
        "    embeddings_batch_response = client.embeddings.create(\n",
        "          model=\"mistral-embed\",\n",
        "          input=input\n",
        "      )\n",
        "    return embeddings_batch_response.data[0].embedding"
      ],
      "id": "fd71dbe6"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It does return a 1024 list of float (the embedding of the input).\n",
        "\n",
        "make a numpy array of all chunk embeddings from the text.\n",
        "\n",
        "(Should take one and half minute)\n",
        "\n",
        "## Store embeddings in vector database"
      ],
      "id": "16354352-ae0a-458b-a6e5-467eee3d3d98"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "import faiss\n",
        "\n",
        "index = faiss.IndexFlatL2(embeddings.shape[1])\n",
        "index.add(embeddings)"
      ],
      "id": "bb5aafcd"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Query\n",
        "\n",
        "## Make an example query\n",
        "\n",
        "Make an embedding for a question like “À quels obstacles est confrontée\n",
        "Alice?”\n",
        "\n",
        "## Search for the most similar chunks"
      ],
      "id": "f0f22440-d290-402f-ab88-0fa98a1c119c"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "D, I = index.search(question_embeddings, k=2) # distance, index"
      ],
      "id": "af6b2db1"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Retrieve the chunks"
      ],
      "id": "9560d0f7-08f0-4c11-ba16-f0fa3f895889"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "#! tags: [solution]\n",
        "retrieved_chunk = [chunks[i] for i in I.tolist()[0]]"
      ],
      "id": "ba3f6e9d"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## RAG prompt\n",
        "\n",
        "Make the RAG query with the following prompt"
      ],
      "id": "0d63441f-c479-42a8-bc7b-9e4b5ab22d35"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "prompt = f\"\"\"\n",
        "Context information is below.\n",
        "---------------------\n",
        "{retrieved_chunk}\n",
        "---------------------\n",
        "Given the context information and not prior knowledge, answer the query.\n",
        "Query: {question}\n",
        "Answer:\n",
        "\"\"\""
      ],
      "id": "3511b2ae"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "'D\\'après le contexte fourni, Alice est confrontée à plusieurs obstacles lors de la partie de croquet bizarre dans *Alice au pays des merveilles* :\\n\\n1. **Un terrain difficile** : Le terrain est rempli de **creux et de bosses**, ce qui rend le jeu imprévisible et compliqué.\\n\\n2. **Des accessoires vivants et imprévisibles** :\\n   - **Les maillets (flamants vivants)** : Le flamant qu’elle utilise comme maillet se retourne constamment pour la regarder avec un air intrigué, ce qui la fait rire et l’empêche de frapper correctement.\\n   - **Les boules (hérissons vivants)** : Les hérissons se déroulent et s’éloignent lentement au moment où elle s’apprête à les frapper.\\n   - **Les arceaux (soldats courbés)** : Les soldats, qui forment les arceaux, se redressent et changent de place sans cesse, perturbant le jeu.\\n\\n3. **Un jeu chaotique et désorganisé** :\\n   - Tous les joueurs jouent **en même temps sans attendre leur tour**, ce qui crée un désordre constant.\\n   - Les participants **se disputent** et **s’arrachent les hérissons**, rendant la partie ingérable.\\n\\n4. **La menace de la Reine** :\\n   - La Reine, en colère, crie régulièrement **« Qu’on lui coupe la tête ! »**, ce qui rend Alice **anxieuse** à l’idée de se disputer avec elle (même si cela ne s’est pas encore produit).\\n\\n5. **Un environnement absurde et déstabilisant** :\\n   - Les règles du jeu sont **incohérentes** et les éléments (animaux, terrain) **ne se comportent pas comme attendu**, ce qui frustre Alice.\\n   - Elle doit aussi **réciter des poèmes** sous la pression du Griffon et de la Simili-Tortue, mais les mots sortent **déformés** (ex. : *\"C’est la voix du homard\"* au lieu de *\"C’est la voix du flemmard\"*), ce qui ajoute à sa confusion.\\n\\nEn résumé, Alice affronte un **monde illogique**, des **obstacles physiques** (terrain, animaux), des **interactions sociales hostiles** (Reine, joueurs chaotiques) et une **perte de contrôle** sur son propre langage, reflétant l’absurdité du Pays des Merveilles.'"
            ]
          }
        }
      ],
      "source": [
        "def run_mistral(user_message, model=\"mistral-large-latest\"):\n",
        "    sleep(1) # Rate-limit\n",
        "    messages = [\n",
        "        {\n",
        "            \"role\": \"user\", \"content\": user_message\n",
        "        }\n",
        "    ]\n",
        "    chat_response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages\n",
        "    )\n",
        "    return (chat_response.choices[0].message.content)\n",
        "\n",
        "run_mistral(prompt)"
      ],
      "id": "c38e420b"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Final\n",
        "\n",
        "Make a function for any question about the book.\n",
        "\n",
        "##"
      ],
      "id": "30ea3dce-f331-4fd9-ac5b-ec85ddd14ffb"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "path": "/Users/fradav/Documents/Dev/Python/Cours-programmation-MIASHS-2025/.venv/share/jupyter/kernels/python3"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": "3"
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  }
}