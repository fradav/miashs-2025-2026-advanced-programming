[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Advanced programming and parallel computing",
    "section": "",
    "text": "Preface\nThis is the course and materials for the lecture on “Advanced programming and parallel computing” at the Paul Valery University of Montpellier, France.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Prerequisites",
    "section": "",
    "text": "1.1 Software required\nYou will need to install the following software on your computer: Visual Studio Code (VSCode), a free and open-source code editor. You’ll have to install the following extensions:",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Prerequisites</span>"
    ]
  },
  {
    "objectID": "intro.html#software-required",
    "href": "intro.html#software-required",
    "title": "1  Prerequisites",
    "section": "",
    "text": "Python extension to have everything you need to work with Python.\n Live Share to enable collaborative editing.\n Continue.dev to have the AI Code Assistant we will use as example in this course.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Prerequisites</span>"
    ]
  },
  {
    "objectID": "intro.html#ai-assistant-getting-api-key.",
    "href": "intro.html#ai-assistant-getting-api-key.",
    "title": "1  Prerequisites",
    "section": "1.2 AI Assistant, getting API Key.",
    "text": "1.2 AI Assistant, getting API Key.\nFor the practical work, you’ll need to get API Keys from Mistral.ai’s “La Plateforme” (it’s completely free). You will need a valid cell phone number for the registration to work. Contact me if this is a problem.\n\n\nMistral Login\n\n\n\nThe first time, you’ll have to create an account. Then, you’ll be able to get your API Key.\nOnce there, Click on “API Keys” tab.\n\n\nMistral API Keys Tab\n\n\n\nClick on “Choose a plan”.\n\n\nNo plan\n\n\n\nChoose “Experiment” plan.\n\n\nExperiment plan\n\n\n\nAccept the conditions.\n\n\nAccept\n\n\n\nGive a phone number for the final check.\n\n\nPhone number check\n\n\n\nConfirm the code.\n\n\nCode received\n\n\n\nIf successful, return on the “AI Keys” Tab and choose “Create a new key”\n\n\nCreate a new key\n\n\n\nChoose a name and an expiration date for your key (could be never if not set).\n\n\nKey name and expiration date\n\n\n\nCopy the key and save it somewhere.\n\n\nKey to copy\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nYou may also create a specific key for Codestral model, which could be used for auto-completion role. Auto-completion role needs specifically tailored models for this task, and the models you can access with the “generic” mistral key aren’t.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Prerequisites</span>"
    ]
  },
  {
    "objectID": "intro.html#vscode-setup",
    "href": "intro.html#vscode-setup",
    "title": "1  Prerequisites",
    "section": "1.3 VSCode setup",
    "text": "1.3 VSCode setup\nWhen you installed your continue vscode extension, it created a .continue folder in your home directory, which is ~/.continue on Linux and Mac, and %USERPROFILE%\\.continue on Windows. Create a .env file there and put your mistral key in it, like this:\nMISTRAL_API_KEY=your_key_here\nOptionally if you got a codestral key put it too:\nCODESTRAL_API_KEY=your_codestral_key_here\nOpen/Create config.yaml file in the same folder and put this in it:\nname: miashs/mistral\nversion: 1.0.0\nschema: v1\nmodels:\n## Uncomment this block if you want to use Codestral for auto-completion, needs a specific key\n#   - name: Codestral\n#     provider: mistral\n#     model: codestral-2508\n#     apiBase: https://codestral.mistral.ai/v1\n#     apiKey: ${{ secrets.CODESTRAL_API_KEY }}\n#     roles:\n#       - autocomplete\n#     defaultCompletionOptions:\n#       contextLength: 256000\n  - name: Devstral\n    provider: mistral\n    model: devstral-medium-latest\n    apiKey: ${{ secrets.MISTRAL_API_KEY }}\n    roles:\n      - chat\n      - edit\n      - apply\n    defaultCompletionOptions:\n      contextLength: 131072\n    capabilities:\n      - tool_use\n# You may choose mistral over devstral if you need image input\n  - name: Mistral\n    provider: mistral\n    model: mistral-medium-latest\n    apiKey: ${{ secrets.MISTRAL_API_KEY }}\n    roles:\n      - chat\n      - edit\n      - apply\n    defaultCompletionOptions:\n      contextLength: 131072\n    capabilities:\n      - tool_use\n      - image_input\n  - name: Codestral Embed\n    provider: mistral\n    model: codestral-embed\n    apiKey: ${{ secrets.MISTRAL_API_KEY }}\n    apiBase: https://api.mistral.ai/v1\n    roles:\n      - embed\ncontext:\n  - provider: code\n  - provider: docs\n    params:\n      maxdepth: 5\n  - provider: diff\n  - provider: terminal\n  - provider: problems\n  - provider: codebase\n    params:\n      nRetrieve: 60\n      nFinal: 25\n  - provider: folder\n    params:\n      nRetrieve: 60\n      nFinal: 25\n  - provider: open\n  - provider: web\n  - provider: tree\n  - provider: clipboard\n  - provider: debugger\n  - provider: repo-map\n  - provider: os\n  - provider: search\n  - provider: url\nCongratulations, you are now set for use of continue AI Code Assistant. You can open the chat panel either by clicking on the Continue in the right bottom status of vscode window or with Cmd + L (Mac) or Ctrl + L (Windows/Linux).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Prerequisites</span>"
    ]
  },
  {
    "objectID": "intro.html#collaborative-editing",
    "href": "intro.html#collaborative-editing",
    "title": "1  Prerequisites",
    "section": "1.4 Collaborative editing",
    "text": "1.4 Collaborative editing\n\nIn the discord channel, I’ll provide you a link to join a collaborative editing session. Don’t click on it, just copy it: \nThen open a new “blank” window in VSCode, which will be exclusively for collaborative session. \nThen, click on the “Live Share” button in the bottom left corner of the window \nClick on the “Join” button \nEither choose anonymous or sign in with your github/microsoft account \n\n\n\n\n\n\n\nAnonymous Guest Name\n\n\n\nIf you choose to sign in, you’ll have to authorize VSCode to access your github/microsoft account. If you choose anonymous, you’ll have to choose a username. Please choose a username that is easily identifiable as yours.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Prerequisites</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html",
    "href": "Courses/01_Code-Assistant.html",
    "title": "2  Code Assistants",
    "section": "",
    "text": "3 History of code editors/assistants\nHistory of code editor features, with a focus on the last three years (2022–2025) and the transformative impact of Large Language Models (LLMs):",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#early-days-text-editors",
    "href": "Courses/01_Code-Assistant.html#early-days-text-editors",
    "title": "2  Code Assistants",
    "section": "3.1 Early Days: Text Editors",
    "text": "3.1 Early Days: Text Editors\n\n1960s–1970s: vi (1976), Emacs (1976)\n\nBasic text manipulation, macros, and syntax highlighting.\n\n\n\n\n\nVi\n\n\n\n\n\n\n\nEmacs",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#the-rise-of-ides",
    "href": "Courses/01_Code-Assistant.html#the-rise-of-ides",
    "title": "2  Code Assistants",
    "section": "3.2 The Rise of IDEs",
    "text": "3.2 The Rise of IDEs\n\n\n\n1980s–1990s: Turbo Pascal (1983), Visual Basic (1991)\n\nIntegrated debugging\nproject management\nbasic autocompletion.\n\n\n\n\n\nTurbo Pascal\n\n\n\n\n\nVisual Basic",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#modern-era-powerful-extensible-ides",
    "href": "Courses/01_Code-Assistant.html#modern-era-powerful-extensible-ides",
    "title": "2  Code Assistants",
    "section": "3.3 Modern Era: Powerful, Extensible IDEs",
    "text": "3.3 Modern Era: Powerful, Extensible IDEs\n\n\n\n2000s: Visual Studio, Eclipse, IntelliJ IDEA\n\\Rightarrow Advanced autocompletion, refactoring, static analysis, and plugin ecosystems.\n\n\n\n\nVisual Studio\n\n\n\n\n\n\n\n\n\n2015: VSCode (based on Electron/Node.js)\n\\Rightarrow Lightweight, open-source, and extensible via marketplace.\n\n\n\n\nVSCode",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#the-language-server-protocol-lsp",
    "href": "Courses/01_Code-Assistant.html#the-language-server-protocol-lsp",
    "title": "2  Code Assistants",
    "section": "3.4 The Language Server Protocol (LSP)",
    "text": "3.4 The Language Server Protocol (LSP)\n2016: Microsoft introduces the Language Server Protocol (LSP)\n\nStandardizes communication between editors/IDEs and language-specific servers.\nEnables features like autocompletion, go-to-definition, linting, and refactoring across many languages.\nDecouples editor development from language tooling.\n\n\n\nLSP Architecture",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#impact-of-lsp-on-developer-experience",
    "href": "Courses/01_Code-Assistant.html#impact-of-lsp-on-developer-experience",
    "title": "2  Code Assistants",
    "section": "3.5 Impact of LSP on Developer Experience",
    "text": "3.5 Impact of LSP on Developer Experience\n\nUnified experience: VSCode, Vim, Emacs, Sublime Text, and more support LSP.\nRapid adoption: Hundreds of languages now have LSP servers.\nConsistent, high-quality tooling regardless of editor.\nPaved the way for advanced features and easier integration of AI assistants.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#the-breakthrough-year",
    "href": "Courses/01_Code-Assistant.html#the-breakthrough-year",
    "title": "2  Code Assistants",
    "section": "4.1 2022: The Breakthrough Year",
    "text": "4.1 2022: The Breakthrough Year\n\n\n\nGitHub Copilot (June 2022)\n\nFirst mainstream LLM-powered code assistant (OpenAI Codex).\nKey features:\n\nCode generation from comments or snippets.\nMulti-language support (Python, JavaScript, Java, etc.).\n\n\n\n\n\n\nGitHub Copilot Autocomplete Demo",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#ai-becomes-ubiquitous",
    "href": "Courses/01_Code-Assistant.html#ai-becomes-ubiquitous",
    "title": "2  Code Assistants",
    "section": "4.2 2023: AI Becomes Ubiquitous",
    "text": "4.2 2023: AI Becomes Ubiquitous\n\nGitHub Copilot X (March 2023)\n\nIntegrated ChatGPT-4 for explanations, test generation, and PR reviews.\nNew features:\n\nNatural language explanations of complex code.\nAutomatic test generation.\nAI-assisted debugging.\n\n\n\n\nJetBrains AI Assistant\n\nNative integration in IntelliJ, PyCharm, etc.\n\nCollaboration tools:\n\nCopilot for Pull Requests, Amazon Q.\n\nVSCode forks:\n\nCursor, Windsurf (by Codeium).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#the-rise-of-autonomous-agents",
    "href": "Courses/01_Code-Assistant.html#the-rise-of-autonomous-agents",
    "title": "2  Code Assistants",
    "section": "4.3 2024: The Rise of Autonomous Agents",
    "text": "4.3 2024: The Rise of Autonomous Agents\n\n\n\nClaude Code (Anthropic, 2024)\n\nAgentic capabilities: Executes tasks (file creation, commits, tests, PRs).\nTerminal integration: Works directly in the terminal.\nHolistic understanding: Cross-file refactors and dependency analysis.\nSecurity: Restrictions for risky commands:refs[1-6,9].\n\n\n\n\n\nClaude Code Demo\n\n\n\n\n\n\n\nGitHub Copilot Enterprise\n\nCustomization for company codebases.\nExtended context (internal docs, Jira tickets).\n\nAdvanced features:\n\nMulti-step agents.\nReal-time visualization (e.g., Artifacts in Claude).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#maturation-and-specialization",
    "href": "Courses/01_Code-Assistant.html#maturation-and-specialization",
    "title": "2  Code Assistants",
    "section": "4.4 2025: Maturation and Specialization",
    "text": "4.4 2025: Maturation and Specialization\n\nDeep integration:\n\nVSCode: Native support for AI agents (Cline, Augment).\nJetBrains: Claude 3.5 and Mellum models:refs[3-4].\nCursor/Windsurf: Popular AI-driven alternatives.\n\nNew features:\n\nMulti-modal editing (code from diagrams, screenshots).\nSpecialized agents for DevOps and security.\nExtreme customization and collaboration.\n\nChallenges:\n\nTechnical debt from “black box” AI-generated code.\nIP concerns and performance issues.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#summary-evolution-of-code-editor-features-20222025",
    "href": "Courses/01_Code-Assistant.html#summary-evolution-of-code-editor-features-20222025",
    "title": "2  Code Assistants",
    "section": "4.5 Summary: Evolution of Code Editor Features (2022–2025)",
    "text": "4.5 Summary: Evolution of Code Editor Features (2022–2025)\n\n\n\n\n\n\n\n\n2022\nLLM-powered code generation\nGitHub Copilot, TabNine\n\n\n\n\n2023\nExplanations, tests, PR reviews\nCopilot X, Amazon Q, JetBrains AI\n\n\n2024\nAutonomous agents, task execution\nClaude Code, Copilot Enterprise\n\n\n2025\nSpecialization, multi-modality\nCursor, Windsurf, Qodo, Continue",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#future-trends",
    "href": "Courses/01_Code-Assistant.html#future-trends",
    "title": "2  Code Assistants",
    "section": "4.6 Future Trends",
    "text": "4.6 Future Trends\n\n\n\nTrend\nBenefits\nChallenges\n\n\n\n\nAI as Co-Pilot\nFaster development, skill augmentation\nOver-reliance, quality control\n\n\nSelf-Healing Editors\nFewer bugs, improved code quality\nFalse positives, transparency\n\n\nLow-Code/No-Code\nAccessibility, rapid prototyping\nLimited customization, maintenance\n\n\nRegulation and Ethics\nSafer, more transparent tools\nCompliance complexity, global fragmentation",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#a-paradigm-shift",
    "href": "Courses/01_Code-Assistant.html#a-paradigm-shift",
    "title": "2  Code Assistants",
    "section": "4.7 A Paradigm Shift",
    "text": "4.7 A Paradigm Shift\n\nFrom manual editing → contextual assistance → AI co-creation.\nChallenge: Mastering tools without compromising quality or security.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#ai-domains",
    "href": "Courses/01_Code-Assistant.html#ai-domains",
    "title": "2  Code Assistants",
    "section": "5.1 AI domains",
    "text": "5.1 AI domains\n\n\nArtificial Intelligence (AI)\n\n\nMachine Learning (ML)\n\n\nDeep Learning (DL)\n\n\nLarge Language Models (LLM)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#train-a-neural-network",
    "href": "Courses/01_Code-Assistant.html#train-a-neural-network",
    "title": "2  Code Assistants",
    "section": "5.2 Train a neural network",
    "text": "5.2 Train a neural network",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#training-a-supervised-machine-learning-model",
    "href": "Courses/01_Code-Assistant.html#training-a-supervised-machine-learning-model",
    "title": "2  Code Assistants",
    "section": "5.3 Training a supervised Machine learning model",
    "text": "5.3 Training a supervised Machine learning model\n\n\nClass of prediction functions f_\\theta: linear, quadratic, trees\nLoss \\mathcal{L}: L^2 norm, CrossEntropy, purity score\nOptimizer: SGD, Adam, …\n\nlearning rate \\eta: \\theta_{k+1} \\gets \\theta_k - \\eta \\nabla_\\theta \\mathcal{L}\nother hyperparameters\n\nDataset:\n\ntraining: \\{(x_i, y_i)\\}_{i} to compute loss between prediction f_{\\theta}(x_i) and label y_i to update \\theta\ntest: only compute performance scores (no more updates !)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#foreword-beware-the-alchemy",
    "href": "Courses/01_Code-Assistant.html#foreword-beware-the-alchemy",
    "title": "2  Code Assistants",
    "section": "6.1 Foreword, beware the Alchemy",
    "text": "6.1 Foreword, beware the Alchemy\n\n\n\n\n\n\n\nMore or less theoretical guarantees\n\nfield of research\ntype of network\nfrom theory to applications: a gap\n\nMyriad of ad-hoc choices, engeenering tricks and empirical observations\nCurrent choices are critical for success: what are their pros and cons?\nTry \\rightarrow Fail \\rightarrow Try again is the current pipeline",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#tensor-algebra",
    "href": "Courses/01_Code-Assistant.html#tensor-algebra",
    "title": "2  Code Assistants",
    "section": "7.1 Tensor algebra",
    "text": "7.1 Tensor algebra\n\nLinear algebra operations on tensors\nMultiLayerPerceptron = sequence of linear operations and non-linear activations\n\n\\Rightarrow input can be anything: images, videos, text, sound, …",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#automatic-differentiation",
    "href": "Courses/01_Code-Assistant.html#automatic-differentiation",
    "title": "2  Code Assistants",
    "section": "7.2 Automatic differentiation",
    "text": "7.2 Automatic differentiation\n\n\n\n\nchain rule to compute gradient with respect to \\theta\nkey tool: backpropagation\n\ndon’t need to store the computation graph entirely\ngradient is fast to compute (a single pass)\nbut memory intensive\n\n\n\n\nf(x)=\\nabla\\frac{x_{1}x_{2} sin(x_3) +e^{x_{1}x_{2}}}{x_3}\n\n\n\\begin{darray}{rcl}\nx_4 & = & x_{1}x_{2}, \\\\\nx_5 & = & sin(x_3), \\\\\nx_6 & = & e^{x_4}, \\\\\nx_7 & = & x_{4}x_{5}, \\\\\nx_8 & = & x_{6}+x_7, \\\\\nx_9 & = & x_{8}/x_3.\n\\end{darray}",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#gradient-descent",
    "href": "Courses/01_Code-Assistant.html#gradient-descent",
    "title": "2  Code Assistants",
    "section": "7.3 Gradient descent",
    "text": "7.3 Gradient descent\nExample with a non-convex function\nf(x_1, x_2) = (x_1^2 + x_2 - 11)^2 + (x_1 + x_2^2 - 7)^2\nPlotly = require(\"plotly.js@2.35.2/dist/plotly.min.js\");\nminX = -5;\nmaxX = 5;\nf = ([x1, x2]) =&gt; (x1**2 + x2 - 11)**2 + (x1 + x2**2 - 7)**2;\n\n{\n  const linspace = d3.scaleLinear().domain([0, 49]).range([minX, maxX]);\n  const X1 = Array.from({length: 50}, (_, i) =&gt; linspace(i));\n  const X2 = Array.from({length: 50}, (_, i) =&gt; linspace(i));\n\n  // Define your function f here\n  const f = ([x1, x2]) =&gt; (x1**2 + x2 - 11)**2 + (x1 + x2**2 - 7)**2;\n\n  const Z = X1.map((x1,i) =&gt; X2.map((x2,j) =&gt; f([x1,x2])));\n\n  const data = [{\n    x: X1.flat(),\n    y: X2.flat(),\n    z: Z,\n    type: 'surface'\n  }];\n\n  const layout = {\n    // title: '',\n    // autosize: true,\n    // width: 100,\n    // height: 100,\n    paper_bgcolor: \"rgba(0,0,0,0)\",\n    plot_bgcolor: \"rgba(0,0,0,0)\",\n    template: 'plotly_dark',\n    // margin: {\n    //   l: 65,\n    //   r: 50,\n    //   b: 65,\n    //   t: 90,\n    // }\n  };\n\n  const div = document.createElement('div');\n  Plotly.newPlot(div, data, layout,{displayModeBar: false});\n  return div;\n}\nfunction grad_descent(x1,x2,step,max_iter) {\n  let grad = f_grad(x1, x2);\n  let iterations = [[x1, x2]];\n  function f_grad(x1, x2) {\n    let df_x1 = 2 * (-7 + x1 + x2**2 + 2 * x1 * (-11 + x1**2 + x2));\n    let df_x2 = 2 * (-11 + x1**2 + x2 + 2 * x2 * (-7 + x1 + x2**2));\n    return [df_x1, df_x2];\n  }\n  var count = 0;\n  while (count &lt; max_iter) {\n    x1 -= step * grad[0];\n    x2 -= step * grad[1];\n    grad = f_grad(x1, x2);\n    if (isFinite(x1) && isFinite(x2) &&\n      (minX &lt; x1) && (x1 &lt; maxX) &&\n      (minX &lt; x2) && (x2 &lt; maxX))\n        iterations.push([x1, x2]);\n    else iterations.push(iterations[count])\n    count += 1\n  }\n  return iterations;\n}\nviewof descent_params = Inputs.form({\n  x1: Inputs.range([minX, maxX], {step: 0.1, value: 0, label: 'x1 initial'}),\n  x2: Inputs.range([minX, maxX], {step: 0.1, value: 0, label: 'x2 initial'}),\n  step: Inputs.range([0.001, 0.04], {step: 0.001, value: 0.01, label: 'Step size'})\n})\n{\n  var iterations = grad_descent(descent_params.x1,descent_params.x2,descent_params.step,20)\n  return Plot.plot({\n    aspectRatio: 1,\n    x: {tickSpacing: 50, label: \"x1 →\"},\n    y: {tickSpacing: 50, label: \"x2 →\"},\n    width: 600,\n    style: {\n      backgroundColor: 'rgba(0,0,0,0)'\n    },\n    marks: [\n      Plot.contour({\n        fill: (x1, x2) =&gt; Math.sqrt((x1**2 + x2 - 11)**2 + (x1 + x2**2 - 7)**2),\n        x1: minX,\n        y1: minX,\n        x2: maxX,\n        y2: maxX,\n        showlegend: false,\n        colorscale: 'RdBu',\n        ncontours: 30\n      }),\n      Plot.line(iterations,{marker: true})\n    ]\n  })\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSensitivity to initial point and step size",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#stochastic-gradient-descent",
    "href": "Courses/01_Code-Assistant.html#stochastic-gradient-descent",
    "title": "2  Code Assistants",
    "section": "7.4 (Stochastic) Gradient descent",
    "text": "7.4 (Stochastic) Gradient descent\n\n\n\n\nnot use all the data at once to compute the gradient\n\nnot feasible in practice (memory wise)\n\nUse mini-batch of data (boostrap samples)\n\none more hyperparameter…\n\n\n\n\n\n\\theta_{k+1} \\leftarrow \\theta_k - \\frac{\\eta}{n}\\sum_{i\\in\\text{batch}}\\nabla_\\theta \\mathcal{L}(f_\\theta(x_i), y_i)\n\n\n\n\n\\Rightarrow No general guarantees of convergence in DL setting",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#optimizers",
    "href": "Courses/01_Code-Assistant.html#optimizers",
    "title": "2  Code Assistants",
    "section": "7.5 Optimizers",
    "text": "7.5 Optimizers\nSGD, Adam, RMSProp\n\nNon-convex optimization research on the subject is still very active, and there is no clear consensus on what is the best optimizer to use in a given situation.\nNo guarantee of global minimum, only local minimum\nNo guarantee of convergence, only convergence in probability",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#more-than-a-pinch-of-non-linearities",
    "href": "Courses/01_Code-Assistant.html#more-than-a-pinch-of-non-linearities",
    "title": "2  Code Assistants",
    "section": "7.6 (More than) a pinch of non-linearities",
    "text": "7.6 (More than) a pinch of non-linearities\n\n\n\n\nLinear Transformations + Non-linear activation functions\nradically enhance the expressive power of the model\nability to explore the space of functions in gradient descent.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#from-text-to-numbers",
    "href": "Courses/01_Code-Assistant.html#from-text-to-numbers",
    "title": "2  Code Assistants",
    "section": "8.1 From text to numbers",
    "text": "8.1 From text to numbers\n\nMain problem: we can’t multiply or do convolutions with words\nSecond problem: many words (for a single language)\nThird problem: how to capture semantics?",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#embeddings",
    "href": "Courses/01_Code-Assistant.html#embeddings",
    "title": "2  Code Assistants",
    "section": "8.2 Embeddings",
    "text": "8.2 Embeddings\n\nDistance between words should not be character based\n\n\n\nwomen\n\n\nwoman\n\n\nwindow\n\n\nwidow",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#embeddings-1",
    "href": "Courses/01_Code-Assistant.html#embeddings-1",
    "title": "2  Code Assistants",
    "section": "Embeddings",
    "text": "Embeddings\n\nDistance between words should not be caracter based\n\n\n\nwidow\n\n\n\n\nwomen\n\n\nwoman\n\n\n\n\nwindow",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#multi-scale-learning-from-text",
    "href": "Courses/01_Code-Assistant.html#multi-scale-learning-from-text",
    "title": "2  Code Assistants",
    "section": "8.3 Multi-scale learning from text",
    "text": "8.3 Multi-scale learning from text\n\nDL layers = capture different levels of dependencies in the data\nattention mechansim applies “multi-scale learning” to data sequences \\Rightarrow e.g. not only words in sentences, but sentences in paragraphs, paragraphs in documents and so on.\n\nPreviously, recurrent networks limited in sequential dependencies,\n\\Rightarrow transformers capture dependencies in the “whole” in parallel (much faster)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#multi-facets-learning-from-text",
    "href": "Courses/01_Code-Assistant.html#multi-facets-learning-from-text",
    "title": "2  Code Assistants",
    "section": "8.4 Multi-facets learning from text",
    "text": "8.4 Multi-facets learning from text\nMulti-head attention mechanism extends the attention mechanism to multifaceted dependencies of the same text components.\nIn the sentence “the cat sat on the rug, and after a few hours, it moved to the mat.” :\n\ncat/rug/mat\nrug/mat\ncat/he\nsat/moved to\n\nAll those groups of words/tokens are multiple facets of the same text and its meaning.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#transformers",
    "href": "Courses/01_Code-Assistant.html#transformers",
    "title": "2  Code Assistants",
    "section": "8.5 Transformers",
    "text": "8.5 Transformers\n\n\n(vaswani2017attention?)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#heart-of-transformers-attention-mechanism",
    "href": "Courses/01_Code-Assistant.html#heart-of-transformers-attention-mechanism",
    "title": "2  Code Assistants",
    "section": "8.6 Heart of Transformers: Attention mechanism",
    "text": "8.6 Heart of Transformers: Attention mechanism\n\n\n\\text{Attention}(Q,K,V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V\n\n\n\n\n\nThree matrices: Query, Key, Value, derived from the input sequence\nd_k: dimension of the key matrix, typically 64 or 128\nwe want to compute a weighted sum of the values V with weights given by the compatibility between the query and the keys\nsoftmax to get a probability distribution\nmulti-head attention: several attention mechanisms in parallel\n\n\n\n\n\n\n\n\n(vaswani2017attention?)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#head-view-of-attention",
    "href": "Courses/01_Code-Assistant.html#head-view-of-attention",
    "title": "2  Code Assistants",
    "section": "8.7 Head view of attention",
    "text": "8.7 Head view of attention\n\n\n\n\n\n\nFigure 8.1: The model view visualizes attention across all heads in a single Transformer layer.\n\n\n\n\n\n\n\n\n\n\n\nEach line shows the attention from one token (left) to another (right).\nLine weight reflects the attention value (ranges from 0 to 1),\nline color identifies the attention head",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#bert-bidirectional-encoder-representations-from-transformers",
    "href": "Courses/01_Code-Assistant.html#bert-bidirectional-encoder-representations-from-transformers",
    "title": "2  Code Assistants",
    "section": "8.8 BERT: Bidirectional Encoder Representations from Transformers",
    "text": "8.8 BERT: Bidirectional Encoder Representations from Transformers\n\nembeddings: represent words as vectors in high dimensions",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#gpt-generative-pre-trained-transformer",
    "href": "Courses/01_Code-Assistant.html#gpt-generative-pre-trained-transformer",
    "title": "2  Code Assistants",
    "section": "8.9 GPT : Generative Pre-trained Transformer",
    "text": "8.9 GPT : Generative Pre-trained Transformer\n\nautoregressive model\ngenerates text by predicting the next token\npre-trained on large corpora of text",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#bert-vs-gpt",
    "href": "Courses/01_Code-Assistant.html#bert-vs-gpt",
    "title": "2  Code Assistants",
    "section": "8.10 BERT vs GPT",
    "text": "8.10 BERT vs GPT\n\n\n\n\n\nBERT\n\n\n\n\n\n\n\nGPT",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#summary-of-llm-types",
    "href": "Courses/01_Code-Assistant.html#summary-of-llm-types",
    "title": "2  Code Assistants",
    "section": "8.11 Summary of LLM types",
    "text": "8.11 Summary of LLM types\n\n\n\nType\nArchitecture\nTraining Objective\nAttention\nUse Cases\n\n\n\n\nBERT (Encoder-Only)\nEncoder stack only\nMasked Language Modeling (MLM)\nBidirectional (sees left and right context)\nClassification, QA, NER, sentiment analysis\n\n\nGPT (Decoder-Only)\nDecoder stack only\nAutoregressive Language Modeling (next token prediction)\nUnidirectional (left-to-right, autoregressive)\nText generation, chatbots, open-ended tasks\n\n\nSeq2Seq (Encoder-Decoder)\nEncoder + Decoder stacks\nSequence-to-sequence (e.g., translation, summarization)\nEncoder: Bidirectional; Decoder: Unidirectional (autoregressive)\nTranslation, summarization, speech recognition, data-to-text\n\n\n\n\n\n\nType\nStrengths\nWeaknesses\nExample Models\nTraining Data\nInference Speed\n\n\n\n\nBERT (Encoder-Only)\nDeep understanding of input; strong for discriminative tasks\nNot designed for generation\nBERT, RoBERTa, DistilBERT\nLarge corpus (masked tokens)\nFast (parallelizable)\n\n\nGPT (Decoder-Only)\nCoherent, fluent generation; open-ended creativity\nNo bidirectional context; limited to left-to-right generation\nGPT-3, GPT-4, Llama\nLarge corpus (autoregressive)\nSlower (autoregressive)\n\n\nSeq2Seq (Encoder-Decoder)\nExplicit input-output mapping; handles sequence transformation\nMore complex; requires aligned input-output pairs\nT5, BART, Transformer (original), Whisper\nParallel corpora (input-output pairs)\nModerate (depends on sequence length)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#generative-llms-base-vs-instruct",
    "href": "Courses/01_Code-Assistant.html#generative-llms-base-vs-instruct",
    "title": "2  Code Assistants",
    "section": "8.12 Generative LLMs, Base vs Instruct",
    "text": "8.12 Generative LLMs, Base vs Instruct\n\nBase models are just predicting the next word (pre-training phase, no task-specific fine-tuning)\nInstruct models are fine-tuned on specific tasks and follow user instructions more effectively.\n\n\n\n\n\n\n\nImportant\n\n\n\nNever use the base model for specific tasks without fine-tuning.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#generative-llms-reasoning-vs-non-reasoning",
    "href": "Courses/01_Code-Assistant.html#generative-llms-reasoning-vs-non-reasoning",
    "title": "2  Code Assistants",
    "section": "8.13 Generative LLMs, Reasoning vs non-Reasoning",
    "text": "8.13 Generative LLMs, Reasoning vs non-Reasoning\n\n(Non-reasoning) models focus on generating coherent text without explicit reasoning capabilities\nReasoning models are designed to perform complex reasoning tasks and can handle multi-step problems, at the cost of increased computational requirements (and budget)\n\n\n\n\n\n\n\nTip\n\n\n\nReasoning addition to LLM have been a breakthrough in the field since end of 2024.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#the-importance-of-the-context-window",
    "href": "Courses/01_Code-Assistant.html#the-importance-of-the-context-window",
    "title": "2  Code Assistants",
    "section": "8.14 The importance of the context window",
    "text": "8.14 The importance of the context window\n\nThe context window is crucial for understanding and generating text.\nIt determines how much information the model can consider at once.\nLarger context windows allow for better understanding of complex queries and generation of more coherent responses\nTypical max context window are in a 16k tokens, latest open-weights local llms are 128/256/512k tokens, frontier llms are 1M+ tokens\nlong context window are computationally expensive and require more memory/gpu ressources.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#what-happens-when-the-context-window-is-exceeded",
    "href": "Courses/01_Code-Assistant.html#what-happens-when-the-context-window-is-exceeded",
    "title": "2  Code Assistants",
    "section": "8.15 What happens when the context window is exceeded?",
    "text": "8.15 What happens when the context window is exceeded?\n\nWhen the context window is exceeded, the model may lose track of important information, leading to less coherent responses.\nStrategies to handle this include:\n\nSummarizing previous context\nUsing external memory stores\nChunking input data\n\n\n\n\n\n\n\n\nCaution\n\n\n\nVery large context (when permitted by the model) isn’t always a good thing: there is chances that the model may become overwhelmed with information, leading to decreased performance AND quality.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#rag-retrieval-augmented-generation",
    "href": "Courses/01_Code-Assistant.html#rag-retrieval-augmented-generation",
    "title": "2  Code Assistants",
    "section": "8.16 RAG (Retrieval-Augmented Generation)",
    "text": "8.16 RAG (Retrieval-Augmented Generation)\n\n\n\n\nRAG combines retrieval-based and generation-based approaches.\nIt retrieves relevant documents from a knowledge base and uses them to inform the generation process.\nThis allows for more accurate and contextually relevant responses.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#reactive-agents",
    "href": "Courses/01_Code-Assistant.html#reactive-agents",
    "title": "2  Code Assistants",
    "section": "9.1 Reactive agents",
    "text": "9.1 Reactive agents\n\n\n\nExamples:\n\nChatbots that respond to user queries with pre-defined answers.\nSimple automation scripts that trigger actions based on specific events, like web search.\nAgentic mode in Code Assistants\n\n\n\n\n\n\n\nWarning\n\n\n\n\\Rightarrow Control is done by the LLM itself with all risks : infinite loops, dangerous unsupervised and potentially dangerous actions etc.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#pipeline-agents",
    "href": "Courses/01_Code-Assistant.html#pipeline-agents",
    "title": "2  Code Assistants",
    "section": "9.2 Pipeline Agents",
    "text": "9.2 Pipeline Agents\n\n\n\nExamples:\n\nRAG queries\nSummarizing documents\nCommunicating with other agents\n\n\n\n\n\n\n\nNote\n\n\n\n\\Rightarrow Control is done by normal, program logic",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#reactive-agent-2025-mcp",
    "href": "Courses/01_Code-Assistant.html#reactive-agent-2025-mcp",
    "title": "2  Code Assistants",
    "section": "9.3 Reactive agent 2025 : MCP",
    "text": "9.3 Reactive agent 2025 : MCP\n\n\nUjjwal Khadka Source",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#ai-for-pipelinesgraphs",
    "href": "Courses/01_Code-Assistant.html#ai-for-pipelinesgraphs",
    "title": "2  Code Assistants",
    "section": "9.4 AI for pipelines/graphs",
    "text": "9.4 AI for pipelines/graphs\n\nLow level (API, almost request-level)\n\nOpenAI API (ubiquitous)\nHuggingface\n\nHigh level (Framework)\n\nLangchain (most popular)\nSemantic Kernel (Microsoft)\nHaystack\nand many many others…\n\n\nSimple request with OpenAI API :\nfrom openai import OpenAI\nclient = OpenAI()\n\nchat_response = client.chat.completions.create(\n    model= \"gpt-4o\",\n    messages = [\n        {\n            \"role\": \"user\",\n            \"content\": \"What is the best French cheese?\",\n        },\n    ]\n)\nprint(chat_response.choices[0].message.content)\nSimple request with LangChain :\nfrom langchain.chat_models import init_chat_model\nfrom langchain_core.messages import HumanMessage, SystemMessage\n\nmodel = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")\n\nmessages = [\n    SystemMessage(\"Translate the following from English into Italian\"),\n    HumanMessage(\"hi!\"),\n]\n\nmodel.invoke(messages)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#mcp-server-example",
    "href": "Courses/01_Code-Assistant.html#mcp-server-example",
    "title": "2  Code Assistants",
    "section": "9.5 MCP Server example",
    "text": "9.5 MCP Server example\nfrom datetime import datetime\nfrom model_context_protocol.server import MCPServer\nfrom model_context_protocol.types import Request, Response\n\ndef get_date_handler(request: Request) -&gt; Response:\n    today = datetime.today().strftime('%Y-%m-%d')\n    return Response(result=today)\n\nif __name__ == '__main__':\n    server = MCPServer(\n        tool_name=\"date-tool\",\n        tool_description=\"Returns the current date in YYYY-MM-DD format.\"\n    )\n    server.register_method('get_date', get_date_handler)\n    print(\"MCP server started. Listening for 'get_date' requests...\")\n    server.serve()",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#the-real-question",
    "href": "Courses/01_Code-Assistant.html#the-real-question",
    "title": "2  Code Assistants",
    "section": "10.1 The real question",
    "text": "10.1 The real question\n\n\n\n\nAre the benefits of using generative AI worth the cost of extra supervision and the additional engineering effort?\n\n\n\nThe general answer is:",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#on-the-other-hand",
    "href": "Courses/01_Code-Assistant.html#on-the-other-hand",
    "title": "2  Code Assistants",
    "section": "10.2 On the other hand…",
    "text": "10.2 On the other hand…\n\n\n\n\n\n\n\n\n\nBeware of vibe-coding",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "3  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Summary</span>"
    ]
  },
  {
    "objectID": "applications.html",
    "href": "applications.html",
    "title": "Appendix A — Applications",
    "section": "",
    "text": "Original (In Percent Format)\nOnline Html (Corrected)\nNotebook (Corrected)\n\n\n\n\nPrompt engineering exercises\n\n\n\n\nAI Agent\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Applications</span>"
    ]
  },
  {
    "objectID": "slides.html",
    "href": "slides.html",
    "title": "Appendix B — Slides in reveal.js",
    "section": "",
    "text": "Code Assistants\n\nNo matching items",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Slides in reveal.js</span>"
    ]
  }
]