[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Advanced programming and parallel computing",
    "section": "",
    "text": "Preface\nThis is the course and materials for the lecture on “Advanced programming and parallel computing” at the Paul Valery University of Montpellier, France.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Software Prerequisites",
    "section": "",
    "text": "1.1 Software required\nYou will need to install the following software on your computer: Visual Studio Code (VSCode), a free and open-source code editor. You’ll have to install the following extensions:",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Software Prerequisites</span>"
    ]
  },
  {
    "objectID": "intro.html#software-required",
    "href": "intro.html#software-required",
    "title": "1  Software Prerequisites",
    "section": "",
    "text": "Python extension to have everything you need to work with Python.\n Live Share to enable collaborative editing.\n Continue.dev to have the AI Code Assistant we will use as example in this course.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Software Prerequisites</span>"
    ]
  },
  {
    "objectID": "intro.html#ai-assistant-getting-api-key.",
    "href": "intro.html#ai-assistant-getting-api-key.",
    "title": "1  Software Prerequisites",
    "section": "1.2 AI Assistant, getting API Key.",
    "text": "1.2 AI Assistant, getting API Key.\nFor the practical work, you’ll need to get API Keys from Mistral.ai’s “La Plateforme” (it’s completely free). You will need a valid cell phone number for the registration to work. Contact me if this is a problem.\n\n\nMistral Login\n\n\n\nThe first time, you’ll have to create an account. Then, you’ll be able to get your API Key.\nOnce there, Click on “API Keys” tab.\n\n\nMistral API Keys Tab\n\n\n\nClick on “Choose a plan”.\n\n\nNo plan\n\n\n\nChoose “Experiment” plan.\n\n\nExperiment plan\n\n\n\nAccept the conditions.\n\n\nAccept\n\n\n\nGive a phone number for the final check.\n\n\nPhone number check\n\n\n\nConfirm the code.\n\n\nCode received\n\n\n\nIf successful, return on the “AI Keys” Tab and choose “Create a new key”\n\n\nCreate a new key\n\n\n\nChoose a name and an expiration date for your key (could be never if not set).\n\n\nKey name and expiration date\n\n\n\nCopy the key and save it somewhere.\n\n\nKey to copy\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nYou may also create a specific key for Codestral model, which could be used for auto-completion role. Auto-completion role needs specifically tailored models for this task, and the models you can access with the “generic” mistral key aren’t.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Software Prerequisites</span>"
    ]
  },
  {
    "objectID": "intro.html#vscode-setup",
    "href": "intro.html#vscode-setup",
    "title": "1  Software Prerequisites",
    "section": "1.3 VSCode setup",
    "text": "1.3 VSCode setup\nWhen you installed your continue vscode extension, it created a .continue folder in your home directory, which is ~/.continue on Linux and Mac, and %USERPROFILE%\\.continue on Windows. Create a .env file there and put your mistral key in it, like this:\nMISTRAL_API_KEY=your_key_here\nOptionally if you got a codestral key put it too:\nCODESTRAL_API_KEY=your_codestral_key_here\nOpen/Create config.yaml file in the same folder and put this in it:\nname: miashs/mistral\nversion: 1.0.0\nschema: v1\nmodels:\n## Uncomment this block if you want to use Codestral for auto-completion, needs a specific key\n#   - name: Codestral\n#     provider: mistral\n#     model: codestral-2508\n#     apiBase: https://codestral.mistral.ai/v1\n#     apiKey: ${{ secrets.CODESTRAL_API_KEY }}\n#     roles:\n#       - autocomplete\n#     defaultCompletionOptions:\n#       contextLength: 256000\n  - name: Devstral\n    provider: mistral\n    model: devstral-medium-latest\n    apiKey: ${{ secrets.MISTRAL_API_KEY }}\n    roles:\n      - chat\n      - edit\n      - apply\n    defaultCompletionOptions:\n      contextLength: 131072\n    capabilities:\n      - tool_use\n# You may choose mistral over devstral if you need image input\n  - name: Mistral\n    provider: mistral\n    model: mistral-medium-latest\n    apiKey: ${{ secrets.MISTRAL_API_KEY }}\n    roles:\n      - chat\n      - edit\n      - apply\n    defaultCompletionOptions:\n      contextLength: 131072\n    capabilities:\n      - tool_use\n      - image_input\n  - name: Codestral Embed\n    provider: mistral\n    model: codestral-embed\n    apiKey: ${{ secrets.MISTRAL_API_KEY }}\n    apiBase: https://api.mistral.ai/v1\n    roles:\n      - embed\ncontext:\n  - provider: code\n  - provider: docs\n    params:\n      maxdepth: 5\n  - provider: diff\n  - provider: terminal\n  - provider: problems\n  - provider: codebase\n    params:\n      nRetrieve: 60\n      nFinal: 25\n  - provider: folder\n    params:\n      nRetrieve: 60\n      nFinal: 25\n  - provider: open\n  - provider: web\n  - provider: tree\n  - provider: clipboard\n  - provider: debugger\n  - provider: repo-map\n  - provider: os\n  - provider: search\n  - provider: url\nCongratulations, you are now set for use of continue AI Code Assistant. You can open the chat panel either by clicking on the Continue in the right bottom status of vscode window or with Cmd + L (Mac) or Ctrl + L (Windows/Linux).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Software Prerequisites</span>"
    ]
  },
  {
    "objectID": "intro.html#collaborative-editing",
    "href": "intro.html#collaborative-editing",
    "title": "1  Software Prerequisites",
    "section": "1.4 Collaborative editing",
    "text": "1.4 Collaborative editing\n\nIn the discord channel, I’ll provide you a link to join a collaborative editing session. Don’t click on it, just copy it: \nThen open a new “blank” window in VSCode, which will be exclusively for collaborative session. \nThen, click on the “Live Share” button in the bottom left corner of the window \nClick on the “Join” button \nEither choose anonymous or sign in with your github/microsoft account \n\n\n\n\n\n\n\nAnonymous Guest Name\n\n\n\nIf you choose to sign in, you’ll have to authorize VSCode to access your github/microsoft account. If you choose anonymous, you’ll have to choose a username. Please choose a username that is easily identifiable as yours.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Software Prerequisites</span>"
    ]
  },
  {
    "objectID": "intro.html#installing-uv",
    "href": "intro.html#installing-uv",
    "title": "1  Software Prerequisites",
    "section": "2.1 Installing uv",
    "text": "2.1 Installing uv\nSee uv installation for your platform.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Software Prerequisites</span>"
    ]
  },
  {
    "objectID": "intro.html#creating-a-new-environment",
    "href": "intro.html#creating-a-new-environment",
    "title": "1  Software Prerequisites",
    "section": "2.2 Creating a new environment",
    "text": "2.2 Creating a new environment\nTo create a new environment, use the following command:\nuv init\nThis will create a new environment within the current directory.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Software Prerequisites</span>"
    ]
  },
  {
    "objectID": "intro.html#adding-packages",
    "href": "intro.html#adding-packages",
    "title": "1  Software Prerequisites",
    "section": "2.3 Adding packages",
    "text": "2.3 Adding packages\nTo add packages to your environment, use the following command:\nuv add package_name\nReplace package_name with the name of the package you want to install. This will install the package in your current environment.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Software Prerequisites</span>"
    ]
  },
  {
    "objectID": "intro.html#running-a-script-online-with-just-a-dependency",
    "href": "intro.html#running-a-script-online-with-just-a-dependency",
    "title": "1  Software Prerequisites",
    "section": "2.4 running a script online with just a dependency",
    "text": "2.4 running a script online with just a dependency\nuv run --with dependency script.py\nThis will execute the script.py file using just the specified dependency as the environment.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Software Prerequisites</span>"
    ]
  },
  {
    "objectID": "intro.html#running-script-with-a-directory",
    "href": "intro.html#running-script-with-a-directory",
    "title": "1  Software Prerequisites",
    "section": "2.5 running script with a directory",
    "text": "2.5 running script with a directory\nuv run --directory dir_env script.py\nThis will execute the script.py file using the specified directory as the working directory.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Software Prerequisites</span>"
    ]
  },
  {
    "objectID": "intro.html#macos",
    "href": "intro.html#macos",
    "title": "1  Software Prerequisites",
    "section": "3.1 MacOS",
    "text": "3.1 MacOS\nAdd this to you vscode settings.json\n    \"jupyter.runStartupCommands\": [\n        \"%colors nocolor\",\n        \"from multiprocessing import spawn\",\n        \"from multiprocessing.spawn import get_preparation_data as __get_preparation_data\",\n        \"def __patched_get_preparation_data(name):\",\n        \"    import sys\",\n        \"    main_mod = sys.modules['__main__']\",\n        \"    main_path = getattr(main_mod, '__file__', None)\",\n        \"    setattr(main_mod, '__file__', None)\",\n        \"    data = __get_preparation_data(name)\",\n        \"    setattr(main_mod, '__file__', main_path)\",\n        \"    return data\",\n        \"spawn.get_preparation_data = __patched_get_preparation_data\",\n        \"del spawn\",\n        \"import sys\",\n        \"from multiprocessing.reduction import ForkingPickler\",\n        \"from types import FunctionType\",\n        \"import cloudpickle\",\n        \"\",\n        \"def reducer_override(obj):\",\n        \"    if type(obj) is FunctionType:\",\n        \"        return (cloudpickle.loads, (cloudpickle.dumps(obj),))\",\n        \"    else:\",\n        \"        return NotImplemented\",\n        \"\",\n        \"ForkingPickler.reducer_override = staticmethod(reducer_override)\"\n    ],",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Software Prerequisites</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html",
    "href": "Courses/01_Code-Assistant.html",
    "title": "2  Code Assistants",
    "section": "",
    "text": "3 History of code editors/assistants\nHistory of code editor features, with a focus on the last three years (2022–2025) and the transformative impact of Large Language Models (LLMs):",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#early-days-text-editors",
    "href": "Courses/01_Code-Assistant.html#early-days-text-editors",
    "title": "2  Code Assistants",
    "section": "3.1 Early Days: Text Editors",
    "text": "3.1 Early Days: Text Editors\n\n1960s–1970s: vi (1976), Emacs (1976)\n\nBasic text manipulation, macros, and syntax highlighting.\n\n\n\n\n\nVi\n\n\n\n\n\n\n\nEmacs",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#the-rise-of-ides",
    "href": "Courses/01_Code-Assistant.html#the-rise-of-ides",
    "title": "2  Code Assistants",
    "section": "3.2 The Rise of IDEs",
    "text": "3.2 The Rise of IDEs\n\n\n\n1980s–1990s: Turbo Pascal (1983), Visual Basic (1991)\n\nIntegrated debugging\nproject management\nbasic autocompletion.\n\n\n\n\n\nTurbo Pascal\n\n\n\n\n\nVisual Basic",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#modern-era-powerful-extensible-ides",
    "href": "Courses/01_Code-Assistant.html#modern-era-powerful-extensible-ides",
    "title": "2  Code Assistants",
    "section": "3.3 Modern Era: Powerful, Extensible IDEs",
    "text": "3.3 Modern Era: Powerful, Extensible IDEs\n\n\n\n2000s: Visual Studio, Eclipse, IntelliJ IDEA\n\\Rightarrow Advanced autocompletion, refactoring, static analysis, and plugin ecosystems.\n\n\n\n\nVisual Studio\n\n\n\n\n\n\n\n\n\n2015: VSCode (based on Electron/Node.js)\n\\Rightarrow Lightweight, open-source, and extensible via marketplace.\n\n\n\n\nVSCode",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#the-language-server-protocol-lsp",
    "href": "Courses/01_Code-Assistant.html#the-language-server-protocol-lsp",
    "title": "2  Code Assistants",
    "section": "3.4 The Language Server Protocol (LSP)",
    "text": "3.4 The Language Server Protocol (LSP)\n2016: Microsoft introduces the Language Server Protocol (LSP)\n\nStandardizes communication between editors/IDEs and language-specific servers.\nEnables features like autocompletion, go-to-definition, linting, and refactoring across many languages.\nDecouples editor development from language tooling.\n\n\n\nLSP Architecture",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#impact-of-lsp-on-developer-experience",
    "href": "Courses/01_Code-Assistant.html#impact-of-lsp-on-developer-experience",
    "title": "2  Code Assistants",
    "section": "3.5 Impact of LSP on Developer Experience",
    "text": "3.5 Impact of LSP on Developer Experience\n\nUnified experience: VSCode, Vim, Emacs, Sublime Text, and more support LSP.\nRapid adoption: Hundreds of languages now have LSP servers.\nConsistent, high-quality tooling regardless of editor.\nPaved the way for advanced features and easier integration of AI assistants.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#the-breakthrough-year",
    "href": "Courses/01_Code-Assistant.html#the-breakthrough-year",
    "title": "2  Code Assistants",
    "section": "4.1 2022: The Breakthrough Year",
    "text": "4.1 2022: The Breakthrough Year\n\n\n\nGitHub Copilot (June 2022)\n\nFirst mainstream LLM-powered code assistant (OpenAI Codex).\nKey features:\n\nCode generation from comments or snippets.\nMulti-language support (Python, JavaScript, Java, etc.).\n\n\n\n\n\n\nGitHub Copilot Autocomplete Demo",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#ai-becomes-ubiquitous",
    "href": "Courses/01_Code-Assistant.html#ai-becomes-ubiquitous",
    "title": "2  Code Assistants",
    "section": "4.2 2023: AI Becomes Ubiquitous",
    "text": "4.2 2023: AI Becomes Ubiquitous\n\nGitHub Copilot X (March 2023)\n\nIntegrated ChatGPT-4 for explanations, test generation, and PR reviews.\nNew features:\n\nNatural language explanations of complex code.\nAutomatic test generation.\nAI-assisted debugging.\n\n\n\n\nJetBrains AI Assistant\n\nNative integration in IntelliJ, PyCharm, etc.\n\nCollaboration tools:\n\nCopilot for Pull Requests, Amazon Q.\n\nVSCode forks:\n\nCursor, Windsurf (by Codeium).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#the-rise-of-autonomous-agents",
    "href": "Courses/01_Code-Assistant.html#the-rise-of-autonomous-agents",
    "title": "2  Code Assistants",
    "section": "4.3 2024: The Rise of Autonomous Agents",
    "text": "4.3 2024: The Rise of Autonomous Agents\n\n\n\nClaude Code (Anthropic, 2024)\n\nAgentic capabilities: Executes tasks (file creation, commits, tests, PRs).\nTerminal integration: Works directly in the terminal.\nHolistic understanding: Cross-file refactors and dependency analysis.\nSecurity: Restrictions for risky commands:refs[1-6,9].\n\n\n\n\n\nClaude Code Demo\n\n\n\n\n\n\n\nGitHub Copilot Enterprise\n\nCustomization for company codebases.\nExtended context (internal docs, Jira tickets).\n\nAdvanced features:\n\nMulti-step agents.\nReal-time visualization (e.g., Artifacts in Claude).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#maturation-and-specialization",
    "href": "Courses/01_Code-Assistant.html#maturation-and-specialization",
    "title": "2  Code Assistants",
    "section": "4.4 2025: Maturation and Specialization",
    "text": "4.4 2025: Maturation and Specialization\n\nDeep integration:\n\nVSCode: Native support for AI agents (Cline, Augment).\nJetBrains: Claude 3.5 and Mellum models:refs[3-4].\nCursor/Windsurf: Popular AI-driven alternatives.\n\nNew features:\n\nMulti-modal editing (code from diagrams, screenshots).\nSpecialized agents for DevOps and security.\nExtreme customization and collaboration.\n\nChallenges:\n\nTechnical debt from “black box” AI-generated code.\nIP concerns and performance issues.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#summary-evolution-of-code-editor-features-20222025",
    "href": "Courses/01_Code-Assistant.html#summary-evolution-of-code-editor-features-20222025",
    "title": "2  Code Assistants",
    "section": "4.5 Summary: Evolution of Code Editor Features (2022–2025)",
    "text": "4.5 Summary: Evolution of Code Editor Features (2022–2025)\n\n\n\n\n\n\n\n\n2022\nLLM-powered code generation\nGitHub Copilot, TabNine\n\n\n\n\n2023\nExplanations, tests, PR reviews\nCopilot X, Amazon Q, JetBrains AI\n\n\n2024\nAutonomous agents, task execution\nClaude Code, Copilot Enterprise\n\n\n2025\nSpecialization, multi-modality\nCursor, Windsurf, Qodo, Continue",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#future-trends",
    "href": "Courses/01_Code-Assistant.html#future-trends",
    "title": "2  Code Assistants",
    "section": "4.6 Future Trends",
    "text": "4.6 Future Trends\n\n\n\nTrend\nBenefits\nChallenges\n\n\n\n\nAI as Co-Pilot\nFaster development, skill augmentation\nOver-reliance, quality control\n\n\nSelf-Healing Editors\nFewer bugs, improved code quality\nFalse positives, transparency\n\n\nLow-Code/No-Code\nAccessibility, rapid prototyping\nLimited customization, maintenance\n\n\nRegulation and Ethics\nSafer, more transparent tools\nCompliance complexity, global fragmentation",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#a-paradigm-shift",
    "href": "Courses/01_Code-Assistant.html#a-paradigm-shift",
    "title": "2  Code Assistants",
    "section": "4.7 A Paradigm Shift",
    "text": "4.7 A Paradigm Shift\n\nFrom manual editing → contextual assistance → AI co-creation.\nChallenge: Mastering tools without compromising quality or security.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#ai-domains",
    "href": "Courses/01_Code-Assistant.html#ai-domains",
    "title": "2  Code Assistants",
    "section": "5.1 AI domains",
    "text": "5.1 AI domains",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#train-a-neural-network",
    "href": "Courses/01_Code-Assistant.html#train-a-neural-network",
    "title": "2  Code Assistants",
    "section": "5.2 Train a neural network",
    "text": "5.2 Train a neural network\n\n\nTanguy Lefort, 2023",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#training-a-supervised-machine-learning-model",
    "href": "Courses/01_Code-Assistant.html#training-a-supervised-machine-learning-model",
    "title": "2  Code Assistants",
    "section": "5.3 Training a supervised Machine learning model",
    "text": "5.3 Training a supervised Machine learning model\n\n\nClass of prediction functions f_\\theta: linear, quadratic, trees\nLoss \\mathcal{L}: L^2 norm, CrossEntropy, purity score\nOptimizer: SGD, Adam, …\n\nlearning rate \\eta: \\theta_{k+1} \\gets \\theta_k - \\eta \\nabla_\\theta \\mathcal{L}\nother hyperparameters\n\nDataset:\n\ntraining: \\{(x_i, y_i)\\}_{i} to compute loss between prediction f_{\\theta}(x_i) and label y_i to update \\theta\ntest: only compute performance scores (no more updates !)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#foreword-beware-the-alchemy",
    "href": "Courses/01_Code-Assistant.html#foreword-beware-the-alchemy",
    "title": "2  Code Assistants",
    "section": "6.1 Foreword, beware the Alchemy",
    "text": "6.1 Foreword, beware the Alchemy\n\n\n\n\n\n\n\nMore or less theoretical guarantees\n\nfield of research\ntype of network\nfrom theory to applications: a gap\n\nMyriad of ad-hoc choices, engeenering tricks and empirical observations\nCurrent choices are critical for success: what are their pros and cons?\nTry \\rightarrow Fail \\rightarrow Try again is the current pipeline",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#tensor-algebra",
    "href": "Courses/01_Code-Assistant.html#tensor-algebra",
    "title": "2  Code Assistants",
    "section": "7.1 Tensor algebra",
    "text": "7.1 Tensor algebra\n\nLinear algebra operations on tensors\nMultiLayerPerceptron = sequence of linear operations and non-linear activations\n\n\\Rightarrow input can be anything: images, videos, text, sound, …",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#automatic-differentiation",
    "href": "Courses/01_Code-Assistant.html#automatic-differentiation",
    "title": "2  Code Assistants",
    "section": "7.2 Automatic differentiation",
    "text": "7.2 Automatic differentiation\n\n\n\nchain rule to compute gradient with respect to \\theta\nkey tool: backpropagation\n\ndon’t need to store the computation graph entirely\ngradient is fast to compute (a single pass)\nbut memory intensive\n\n\n\nf(x)=\\nabla\\frac{x_{1}x_{2} sin(x_3) +e^{x_{1}x_{2}}}{x_3}\n\n\n\\begin{darray}{rcl}\nx_4 & = & x_{1}x_{2}, \\\\\nx_5 & = & sin(x_3), \\\\\nx_6 & = & e^{x_4}, \\\\\nx_7 & = & x_{4}x_{5}, \\\\\nx_8 & = & x_{6}+x_7, \\\\\nx_9 & = & x_{8}/x_3.\n\\end{darray}",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#gradient-descent",
    "href": "Courses/01_Code-Assistant.html#gradient-descent",
    "title": "2  Code Assistants",
    "section": "7.3 Gradient descent",
    "text": "7.3 Gradient descent\nExample with a non-convex function\nf(x_1, x_2) = (x_1^2 + x_2 - 11)^2 + (x_1 + x_2^2 - 7)^2\n\n\n\n\nCode\nPlotly = require(\"plotly.js@2.35.2/dist/plotly.min.js\");\n\nminX = -5;\nmaxX = 5;\n\nf = ([x1, x2]) =&gt; (x1**2 + x2 - 11)**2 + (x1 + x2**2 - 7)**2;\n\n{\n  const linspace = d3.scaleLinear().domain([0, 49]).range([minX, maxX]);\n  const X1 = Array.from({length: 50}, (_, i) =&gt; linspace(i));\n  const X2 = Array.from({length: 50}, (_, i) =&gt; linspace(i));\n\n  // Define your function f here\n  const f = ([x1, x2]) =&gt; (x1**2 + x2 - 11)**2 + (x1 + x2**2 - 7)**2;\n\n  const Z = X1.map((x1,i) =&gt; X2.map((x2,j) =&gt; f([x1,x2])));\n\n  const data = [{\n    x: X1.flat(),\n    y: X2.flat(),\n    z: Z,\n    type: 'surface'\n  }];\n\n  const layout = {\n    // title: '',\n    autosize: false,\n    width: 400,\n    height: 400,\n    paper_bgcolor: \"rgba(0,0,0,0)\",\n    plot_bgcolor: \"rgba(0,0,0,0)\",\n    template: 'plotly_dark',\n    margin: {\n      l: 0,\n      r: 0,\n      b: 0,\n      t: 0\n    }\n  };\n\n  const div = document.createElement('div');\n  Plotly.newPlot(div, data, layout,{displayModeBar: false});\n  return div;\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nfunction grad_descent(x1,x2,step,max_iter) {\n  let grad = f_grad(x1, x2);\n  let iterations = [[x1, x2]];\n  function f_grad(x1, x2) {\n    let df_x1 = 2 * (-7 + x1 + x2**2 + 2 * x1 * (-11 + x1**2 + x2));\n    let df_x2 = 2 * (-11 + x1**2 + x2 + 2 * x2 * (-7 + x1 + x2**2));\n    return [df_x1, df_x2];\n  }\n  var count = 0;\n  while (count &lt; max_iter) {\n    x1 -= step * grad[0];\n    x2 -= step * grad[1];\n    grad = f_grad(x1, x2);\n    if (isFinite(x1) && isFinite(x2) &&\n      (minX &lt; x1) && (x1 &lt; maxX) &&\n      (minX &lt; x2) && (x2 &lt; maxX))\n        iterations.push([x1, x2]);\n    else iterations.push(iterations[count])\n    count += 1\n  }\n  return iterations;\n}\n\nviewof descent_params = Inputs.form({\n  x1: Inputs.range([minX, maxX], {step: 0.1, value: 0, label: 'x1 initial'}),\n  x2: Inputs.range([minX, maxX], {step: 0.1, value: 0, label: 'x2 initial'}),\n  step: Inputs.range([0.001, 0.04], {step: 0.001, value: 0.01, label: 'Step size'})\n})\n\nprefix = Inputs.text().classList[0];\n\n{\n  d3.selectAll(`.${prefix}`).style(\"font-size\", \"16px\");\n  var iterations = grad_descent(descent_params.x1,descent_params.x2,descent_params.step,20)\n  return Plot.plot({\n    aspectRatio: 1,\n    x: {tickSpacing: 50, label: \"x1 →\"},\n    y: {tickSpacing: 50, label: \"x2 →\"},\n    width: 600,\n    style: {\n      backgroundColor: 'rgba(0,0,0,0)'\n    },\n    marks: [\n      Plot.contour({\n        fill: (x1, x2) =&gt; Math.sqrt((x1**2 + x2 - 11)**2 + (x1 + x2**2 - 7)**2),\n        x1: minX,\n        y1: minX,\n        x2: maxX,\n        y2: maxX,\n        showlegend: false,\n        colorscale: 'RdBu',\n        ncontours: 30\n      }),\n      Plot.line(iterations,{marker: true})\n    ]\n  })\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSensitivity to initial point and step size",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#stochastic-gradient-descent",
    "href": "Courses/01_Code-Assistant.html#stochastic-gradient-descent",
    "title": "2  Code Assistants",
    "section": "7.4 (Stochastic) Gradient descent",
    "text": "7.4 (Stochastic) Gradient descent\n\n\n\n\nnot use all the data at once to compute the gradient\n\nnot feasible in practice (memory wise)\n\nUse mini-batch of data (boostrap samples)\n\none more hyperparameter…\n\n\n\n\n\n\\theta_{k+1} \\leftarrow \\theta_k - \\frac{\\eta}{n}\\sum_{i\\in\\text{batch}}\\nabla_\\theta \\mathcal{L}(f_\\theta(x_i), y_i)\n\n\n\n\n\\Rightarrow No general guarantees of convergence in DL setting",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#optimizers",
    "href": "Courses/01_Code-Assistant.html#optimizers",
    "title": "2  Code Assistants",
    "section": "7.5 Optimizers",
    "text": "7.5 Optimizers\nSGD, Adam, RMSProp\n\nNon-convex optimization research on the subject is still very active, and there is no clear consensus on what is the best optimizer to use in a given situation.\nNo guarantee of global minimum, only local minimum\nNo guarantee of convergence, only convergence in probability",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#more-than-a-pinch-of-non-linearities",
    "href": "Courses/01_Code-Assistant.html#more-than-a-pinch-of-non-linearities",
    "title": "2  Code Assistants",
    "section": "7.6 (More than) a pinch of non-linearities",
    "text": "7.6 (More than) a pinch of non-linearities\n\n\n\n\nLinear Transformations + Non-linear activation functions\nradically enhance the expressive power of the model\nability to explore the space of functions in gradient descent.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#from-text-to-numbers",
    "href": "Courses/01_Code-Assistant.html#from-text-to-numbers",
    "title": "2  Code Assistants",
    "section": "8.1 From text to numbers",
    "text": "8.1 From text to numbers\n\nMain problem: we can’t multiply or do convolutions with words\nSecond problem: many words (for a single language)\nThird problem: how to capture semantics?",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#embeddings-2",
    "href": "Courses/01_Code-Assistant.html#embeddings-2",
    "title": "2  Code Assistants",
    "section": "8.2 Embeddings",
    "text": "8.2 Embeddings\n\nDistance between words should not be character based\n\n\n\n\n\n\n\n\\Rightarrow\n\n\n\n\n\n\n\nTanguy Lefort, 2023",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#multi-scale-learning-from-text",
    "href": "Courses/01_Code-Assistant.html#multi-scale-learning-from-text",
    "title": "2  Code Assistants",
    "section": "8.3 Multi-scale learning from text",
    "text": "8.3 Multi-scale learning from text\n\nDL layers = capture different levels of dependencies in the data\nattention mechansim applies “multi-scale learning” to data sequences \\Rightarrow e.g. not only words in sentences, but sentences in paragraphs, paragraphs in documents and so on.\n\n\\Rightarrow transformers capture dependencies in the “whole”",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#multi-facets-learning-from-text",
    "href": "Courses/01_Code-Assistant.html#multi-facets-learning-from-text",
    "title": "2  Code Assistants",
    "section": "8.4 Multi-facets learning from text",
    "text": "8.4 Multi-facets learning from text\nMulti-head attention mechanism extends the attention mechanism to multifaceted dependencies of the same text components.\nIn the sentence “the cat sat on the rug, and after a few hours, it moved to the mat.” :\n\ncat/rug/mat\nrug/mat\ncat/he\nsat/moved to\n\n\\Rightarrow All those groups of words/tokens are multiple facets of the same text and its meaning.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#transformers",
    "href": "Courses/01_Code-Assistant.html#transformers",
    "title": "2  Code Assistants",
    "section": "8.5 Transformers",
    "text": "8.5 Transformers\n\n\nVaswani et al. (2017)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#heart-of-transformers-attention-mechanism",
    "href": "Courses/01_Code-Assistant.html#heart-of-transformers-attention-mechanism",
    "title": "2  Code Assistants",
    "section": "8.6 Heart of Transformers: Attention mechanism",
    "text": "8.6 Heart of Transformers: Attention mechanism\n\n\n\\text{Attention}(Q,K,V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V\n\n\n\n\n\nThree matrices: Query, Key, Value, derived from the input sequence\nd_k: dimension of the key matrix, typically 64 or 128\nwe want to compute a weighted sum of the values V with weights given by the compatibility between the query and the keys\nsoftmax to get a probability distribution\nmulti-head attention: several attention mechanisms in parallel\n\n\n\n\n\n\n\n\nVaswani et al. (2017)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#head-view-of-attention",
    "href": "Courses/01_Code-Assistant.html#head-view-of-attention",
    "title": "2  Code Assistants",
    "section": "8.7 Head view of attention",
    "text": "8.7 Head view of attention\n\n\n\n\n\n\nFigure 8.1: The model view visualizes attention across all heads in a single Transformer layer.\n\n\n\n\n\n\n\n\n\n\n\nEach line shows the attention from one token (left) to another (right).\nLine weight reflects the attention value (ranges from 0 to 1),\nline color identifies the attention head",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#bert-bidirectional-encoder-representations-from-transformers",
    "href": "Courses/01_Code-Assistant.html#bert-bidirectional-encoder-representations-from-transformers",
    "title": "2  Code Assistants",
    "section": "8.8 BERT: Bidirectional Encoder Representations from Transformers",
    "text": "8.8 BERT: Bidirectional Encoder Representations from Transformers\n\nembeddings: represent words as vectors in high dimensions",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#gpt-generative-pre-trained-transformer",
    "href": "Courses/01_Code-Assistant.html#gpt-generative-pre-trained-transformer",
    "title": "2  Code Assistants",
    "section": "8.9 GPT : Generative Pre-trained Transformer",
    "text": "8.9 GPT : Generative Pre-trained Transformer\n\nautoregressive model\ngenerates text by predicting the next token\npre-trained on large corpora of text",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#bert-vs-gpt",
    "href": "Courses/01_Code-Assistant.html#bert-vs-gpt",
    "title": "2  Code Assistants",
    "section": "8.10 BERT vs GPT",
    "text": "8.10 BERT vs GPT\n\n\n\n\n\nBERT\n\n\n\n\n\n\n\nGPT",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#summary-of-llm-types",
    "href": "Courses/01_Code-Assistant.html#summary-of-llm-types",
    "title": "2  Code Assistants",
    "section": "8.11 Summary of LLM types",
    "text": "8.11 Summary of LLM types\n\n\n\nType\nArchitecture\nTraining Objective\nAttention\nUse Cases\n\n\n\n\nBERT (Encoder-Only)\nEncoder stack only\nMasked Language Modeling (MLM)\nBidirectional (sees left and right context)\nClassification, QA, NER, sentiment analysis\n\n\nGPT (Decoder-Only)\nDecoder stack only\nAutoregressive Language Modeling (next token prediction)\nUnidirectional (left-to-right, autoregressive)\nText generation, chatbots, open-ended tasks\n\n\nSeq2Seq (Encoder-Decoder)\nEncoder + Decoder stacks\nSequence-to-sequence (e.g., translation, summarization)\nEncoder: Bidirectional; Decoder: Unidirectional (autoregressive)\nTranslation, summarization, speech recognition, data-to-text\n\n\n\n\n\n\nType\nStrengths\nWeaknesses\nExample Models\nTraining Data\nInference Speed\n\n\n\n\nBERT (Encoder-Only)\nDeep understanding of input; strong for discriminative tasks\nNot designed for generation\nBERT, RoBERTa, DistilBERT\nLarge corpus (masked tokens)\nFast (parallelizable)\n\n\nGPT (Decoder-Only)\nCoherent, fluent generation; open-ended creativity\nNo bidirectional context; limited to left-to-right generation\nGPT-3, GPT-4, Llama\nLarge corpus (autoregressive)\nSlower (autoregressive)\n\n\nSeq2Seq (Encoder-Decoder)\nExplicit input-output mapping; handles sequence transformation\nMore complex; requires aligned input-output pairs\nT5, BART, Transformer (original), Whisper\nParallel corpora (input-output pairs)\nModerate (depends on sequence length)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#generative-llms-base-vs-instruct",
    "href": "Courses/01_Code-Assistant.html#generative-llms-base-vs-instruct",
    "title": "2  Code Assistants",
    "section": "8.12 Generative LLMs, Base vs Instruct",
    "text": "8.12 Generative LLMs, Base vs Instruct\n\nBase models are just predicting the next word (pre-training phase, no task-specific fine-tuning)\nInstruct models are fine-tuned on specific tasks and follow user instructions more effectively.\n\n\n\n\n\n\n\nImportant\n\n\n\nNever use the base model for specific tasks without fine-tuning.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#generative-llms-reasoning-vs-non-reasoning",
    "href": "Courses/01_Code-Assistant.html#generative-llms-reasoning-vs-non-reasoning",
    "title": "2  Code Assistants",
    "section": "8.13 Generative LLMs, Reasoning vs non-Reasoning",
    "text": "8.13 Generative LLMs, Reasoning vs non-Reasoning\n\n(Non-reasoning) models focus on generating coherent text without explicit reasoning capabilities\nReasoning models are designed to perform complex reasoning tasks and can handle multi-step problems, at the cost of increased computational requirements (and budget)\n\n\n\n\n\n\n\nTip\n\n\n\nReasoning addition to LLM have been a breakthrough in the field since end of 2024.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#the-importance-of-the-context-window",
    "href": "Courses/01_Code-Assistant.html#the-importance-of-the-context-window",
    "title": "2  Code Assistants",
    "section": "8.14 The importance of the context window",
    "text": "8.14 The importance of the context window\n\nThe context window is crucial for understanding and generating text.\nIt determines how much information the model can consider at once.\nLarger context windows allow for better understanding of complex queries and generation of more coherent responses\nTypical max context window are in a 16k tokens, latest open-weights local llms are 128/256/512k tokens, frontier llms are 1M+ tokens\nlong context window are computationally expensive and require more memory/gpu ressources.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#what-happens-when-the-context-window-is-exceeded",
    "href": "Courses/01_Code-Assistant.html#what-happens-when-the-context-window-is-exceeded",
    "title": "2  Code Assistants",
    "section": "8.15 What happens when the context window is exceeded?",
    "text": "8.15 What happens when the context window is exceeded?\n\nWhen the context window is exceeded, the model may lose track of important information, leading to less coherent responses.\nStrategies to handle this include:\n\nSummarizing previous context\nUsing external memory stores\nChunking input data\n\n\n\n\n\n\n\n\nCaution\n\n\n\nVery large context (when permitted by the model) isn’t always a good thing: there is chances that the model may become overwhelmed with information, leading to decreased performance AND quality.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#rag-retrieval-augmented-generation",
    "href": "Courses/01_Code-Assistant.html#rag-retrieval-augmented-generation",
    "title": "2  Code Assistants",
    "section": "8.16 RAG (Retrieval-Augmented Generation)",
    "text": "8.16 RAG (Retrieval-Augmented Generation)\n\n\n\n\nRAG combines retrieval-based and generation-based approaches.\nIt retrieves relevant documents from a knowledge base and uses them to inform the generation process.\nThis allows for more accurate and contextually relevant responses.\n\n\n\n\n\n\n\n\nTurtlecrown, Wikipedia",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#reactive-agents",
    "href": "Courses/01_Code-Assistant.html#reactive-agents",
    "title": "2  Code Assistants",
    "section": "9.1 Reactive agents",
    "text": "9.1 Reactive agents\n\n\n\nExamples:\n\nChatbots that respond to user queries with pre-defined answers.\nSimple automation scripts that trigger actions based on specific events, like web search.\nAgentic mode in Code Assistants\n\n\n\n\n\n\n\nWarning\n\n\n\n\\Rightarrow Control is done by the LLM itself with all risks : infinite loops, unsupervised and potentially dangerous actions etc.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#pipeline-agents",
    "href": "Courses/01_Code-Assistant.html#pipeline-agents",
    "title": "2  Code Assistants",
    "section": "9.2 Pipeline Agents",
    "text": "9.2 Pipeline Agents\n\n\n\nExamples:\n\nRAG queries\nSummarizing documents\nCommunicating with other agents\n\n\n\n\n\n\n\nNote\n\n\n\n\\Rightarrow Control is done by normal, program logic",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#reactive-agent-2025-mcp",
    "href": "Courses/01_Code-Assistant.html#reactive-agent-2025-mcp",
    "title": "2  Code Assistants",
    "section": "9.3 Reactive agent 2025 : MCP",
    "text": "9.3 Reactive agent 2025 : MCP\n\n\nUjjwal Khadka Source",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#ai-for-pipelinesgraphs",
    "href": "Courses/01_Code-Assistant.html#ai-for-pipelinesgraphs",
    "title": "2  Code Assistants",
    "section": "9.4 AI for pipelines/graphs",
    "text": "9.4 AI for pipelines/graphs\n\nLow level (API, almost request-level)\n\nOpenAI API (ubiquitous)\nHuggingface\n\nHigh level (Framework)\n\nLangchain (most popular)\nSemantic Kernel (Microsoft)\nHaystack\nand many many others…\n\n\nSimple request with OpenAI API :\nfrom openai import OpenAI\nclient = OpenAI()\n\nchat_response = client.chat.completions.create(\n    model= \"gpt-4o\",\n    messages = [\n        {\n            \"role\": \"user\",\n            \"content\": \"What is the best French cheese?\",\n        },\n    ]\n)\nprint(chat_response.choices[0].message.content)\nSimple request with LangChain :\nfrom langchain.chat_models import init_chat_model\nfrom langchain_core.messages import HumanMessage, SystemMessage\n\nmodel = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")\n\nmessages = [\n    SystemMessage(\"Translate the following from English into Italian\"),\n    HumanMessage(\"hi!\"),\n]\n\nmodel.invoke(messages)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#mcp-server-example",
    "href": "Courses/01_Code-Assistant.html#mcp-server-example",
    "title": "2  Code Assistants",
    "section": "9.5 MCP Server example",
    "text": "9.5 MCP Server example\nfrom datetime import datetime\nfrom mcp.server.fastmcp import FastMCP\n\n# Create an MCP server\nmcp = FastMCP(\"GetTime\")\n\n@mcp.tool()\ndef get_date() -&gt; str:\n    \"\"\"Returns the current date in YYYY-MM-DD format.\"\"\"\n    return datetime.today().strftime('%Y-%m-%d')",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#the-real-question",
    "href": "Courses/01_Code-Assistant.html#the-real-question",
    "title": "2  Code Assistants",
    "section": "10.1 The real question",
    "text": "10.1 The real question\n\n\n\n\nAre the benefits of using generative AI worth the cost of extra supervision and the additional engineering effort?\n\n\n\nThe general answer is:",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/01_Code-Assistant.html#on-the-other-hand",
    "href": "Courses/01_Code-Assistant.html#on-the-other-hand",
    "title": "2  Code Assistants",
    "section": "10.2 On the other hand…",
    "text": "10.2 On the other hand…\n\n\n\n\n\n\n\n\n\nBeware of vibe-coding",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Code Assistants</span>"
    ]
  },
  {
    "objectID": "Courses/02_Parallel-intro.html",
    "href": "Courses/02_Parallel-intro.html",
    "title": "3  Introduction to parallel computing",
    "section": "",
    "text": "4 Parallel computing: the intuition",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introduction to parallel computing</span>"
    ]
  },
  {
    "objectID": "Courses/02_Parallel-intro.html#computing",
    "href": "Courses/02_Parallel-intro.html#computing",
    "title": "3  Introduction to parallel computing",
    "section": "4.1 Computing ?",
    "text": "4.1 Computing ?\n\na computation = a succession of tasks to complete\na task \\approx a single command/action or a group of commands/actions\n\n\n\n\nExample 1:\n\n\nExample 2:\n\n\n\n\n# task i:\n# sum of elements at index i\n# from two vectors\nfor i in range(10):\n    res[i] = a[i] + b[i]\n\n\n# task 1: matrix product\nC = A @ B\n# task 2: colwise sum over matrix C\nnp.sum(C,axis=0)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introduction to parallel computing</span>"
    ]
  },
  {
    "objectID": "Courses/02_Parallel-intro.html#why-parallel-computing",
    "href": "Courses/02_Parallel-intro.html#why-parallel-computing",
    "title": "3  Introduction to parallel computing",
    "section": "4.2 Why parallel computing?",
    "text": "4.2 Why parallel computing?\n\nObjective: accelerate computations &lt;=&gt; reduce computation time\nIdea: run multiple tasks in parallel instead of sequentially",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introduction to parallel computing</span>"
    ]
  },
  {
    "objectID": "Courses/02_Parallel-intro.html#context-level-1",
    "href": "Courses/02_Parallel-intro.html#context-level-1",
    "title": "3  Introduction to parallel computing",
    "section": "4.3 Context (level 1)",
    "text": "4.3 Context (level 1)\n\ndifferent tasks to complete\none or more workers to complete the tasks",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introduction to parallel computing</span>"
    ]
  },
  {
    "objectID": "Courses/02_Parallel-intro.html#sequential-computing",
    "href": "Courses/02_Parallel-intro.html#sequential-computing",
    "title": "3  Introduction to parallel computing",
    "section": "4.4 Sequential computing",
    "text": "4.4 Sequential computing\n\n\n\n\nn tasks to complete (n&gt;1)\n1 worker\n\nTotal time (exercise)\n\n\\sum_{i=1}^n t_i \\sim O(n)\\ with t_i time to complete task i}",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introduction to parallel computing</span>"
    ]
  },
  {
    "objectID": "Courses/02_Parallel-intro.html#parallel-computing-the-most-simple-case",
    "href": "Courses/02_Parallel-intro.html#parallel-computing-the-most-simple-case",
    "title": "3  Introduction to parallel computing",
    "section": "4.5 Parallel computing (the most simple case)",
    "text": "4.5 Parallel computing (the most simple case)\n\n\n\n\n\n\nn tasks to complete (n&gt;1)\np workers (p&gt;=n)\n\n\n\n\nTotal time (exercise)\n\n\\underset{i=1,\\dots,n}{\\text{max}}\\{t_i\\}\\sim O(1)\\ with t_i time to complete task i\n\n\n\nPotential bottleneck? (exercise)\n\nnot enough workers to complete all tasks",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introduction to parallel computing</span>"
    ]
  },
  {
    "objectID": "Courses/02_Parallel-intro.html#task-scheduling",
    "href": "Courses/02_Parallel-intro.html#task-scheduling",
    "title": "3  Introduction to parallel computing",
    "section": "4.6 Task scheduling",
    "text": "4.6 Task scheduling\n\n\n\n\nn tasks to complete (n&gt;1)\np workers (p&lt;n)\n\nNeed: assign multiple tasks to each worker (and manage this assignment)\n\n\n\n\n\n\n\n\n\n\nTotal time (exercise)\n\n\\underset{k=1,\\dots,p}{\\text{max}}\\{T_k\\}\\sim O(n/p)\\ with T_k = \\sum_{i\\in I_k} t_i, total time to complete all tasks assigned to worker k (where I_k is the set of indexes of tasks assigned to worker k)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introduction to parallel computing</span>"
    ]
  },
  {
    "objectID": "Courses/02_Parallel-intro.html#illustration-parallel-computing-simple-case",
    "href": "Courses/02_Parallel-intro.html#illustration-parallel-computing-simple-case",
    "title": "3  Introduction to parallel computing",
    "section": "4.7 Illustration: parallel computing (simple case)",
    "text": "4.7 Illustration: parallel computing (simple case)\n\n\n\na task = “wait 1 \\mus”\nObjective: run 100 tasks\nNumber of workers: 1, 2, 4, 6, 8\n\nWhy is the time gain not linear?\n\n\n\n10 repetitions in each configurations",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introduction to parallel computing</span>"
    ]
  },
  {
    "objectID": "Courses/02_Parallel-intro.html#context-level-2",
    "href": "Courses/02_Parallel-intro.html#context-level-2",
    "title": "3  Introduction to parallel computing",
    "section": "4.8 Context (level 2)",
    "text": "4.8 Context (level 2)\n\ndifferent tasks to complete\nmultiple workers to complete the tasks\none or more working resources1\n\nPotential bottleneck? (exercise)\n\nnot enough resources for all workers",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introduction to parallel computing</span>"
    ]
  },
  {
    "objectID": "Courses/02_Parallel-intro.html#resource-management",
    "href": "Courses/02_Parallel-intro.html#resource-management",
    "title": "3  Introduction to parallel computing",
    "section": "4.9 Resource management",
    "text": "4.9 Resource management\n\n\n\n\nn tasks to complete (n&gt;1)\np workers (p&lt;n)\nq working resources (q&lt;p)\n\nNeed:\n\nassign workers to each resource (and manage this assignment)\n\nTotal time = ? (exercise)\nPotential issues? (exercise)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introduction to parallel computing</span>"
    ]
  },
  {
    "objectID": "Courses/02_Parallel-intro.html#resource-management-1",
    "href": "Courses/02_Parallel-intro.html#resource-management-1",
    "title": "3  Introduction to parallel computing",
    "section": "4.10 Resource management",
    "text": "4.10 Resource management\nTotal time = \\text{max}_{\\ell=1,\\dots,q}\\{\\tau_\\ell\\}\\sim O(n/q)\nwith \\tau_\\ell = \\sum_{i\\in J_\\ell} t_i = total time to complete all tasks done on resource \\ell (where J_\\ell is the set of indexes of tasks assigned done on resource \\ell)\nPotential issues? multiple workers want to use the same working resources\n\nthey have to wait for their turn (workers are not working all the time)\nrisk to jam2 resource access (organizing resource access takes time)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introduction to parallel computing</span>"
    ]
  },
  {
    "objectID": "Courses/02_Parallel-intro.html#illustration-overhead-for-resource-access",
    "href": "Courses/02_Parallel-intro.html#illustration-overhead-for-resource-access",
    "title": "3  Introduction to parallel computing",
    "section": "4.11 Illustration: overhead for resource access",
    "text": "4.11 Illustration: overhead for resource access\n\n\n\na task = “wait 1 \\mus”\nObjective: run 100 tasks\n8 computing units\nNumber of workers: 1, 2, 4, 8, 16, 32\n\n\n\n\n10 repetitions in each configurations",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introduction to parallel computing</span>"
    ]
  },
  {
    "objectID": "Courses/02_Parallel-intro.html#context-level-3-realistic",
    "href": "Courses/02_Parallel-intro.html#context-level-3-realistic",
    "title": "3  Introduction to parallel computing",
    "section": "4.12 Context (level 3: realistic)",
    "text": "4.12 Context (level 3: realistic)\n\ndifferent tasks to complete\nmultiple workers to complete the tasks\none or more working resources\n\nInput/Output (I/O)\n\nInput: each task requires some materials (data) to be completed, these materials are stored in a storage area (memory)\nOutput: each task returns a result that need to be put in the storage area (memory)\n\nExamples: vector/matrix/array operations, process the content of multiple files",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introduction to parallel computing</span>"
    ]
  },
  {
    "objectID": "Courses/02_Parallel-intro.html#inputoutput-management",
    "href": "Courses/02_Parallel-intro.html#inputoutput-management",
    "title": "3  Introduction to parallel computing",
    "section": "4.13 Input/Output management",
    "text": "4.13 Input/Output management\n\nn tasks to complete (n&gt;1)\np workers (p&lt;n)\nq working resources (q&lt;p)\ntasks need input (data) and produce output (results)\n\nNeed:\n\nload input (data) from storage when needed by a worker to complete a task\nwrite output (result) to storage when a task is completed\n\nTotal time = ? (exercise)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introduction to parallel computing</span>"
    ]
  },
  {
    "objectID": "Courses/02_Parallel-intro.html#parallel-computing-realistic-model",
    "href": "Courses/02_Parallel-intro.html#parallel-computing-realistic-model",
    "title": "3  Introduction to parallel computing",
    "section": "4.14 Parallel computing: realistic model",
    "text": "4.14 Parallel computing: realistic model",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introduction to parallel computing</span>"
    ]
  },
  {
    "objectID": "Courses/02_Parallel-intro.html#computing-time-and-potential-bottleneck",
    "href": "Courses/02_Parallel-intro.html#computing-time-and-potential-bottleneck",
    "title": "3  Introduction to parallel computing",
    "section": "4.15 Computing time and potential bottleneck",
    "text": "4.15 Computing time and potential bottleneck\nTotal time = \\text{max}_{\\ell=1,\\dots,q}\\{\\tau_\\ell\\}\nwith \\tau_\\ell = \\sum_{i\\in J_\\ell} t_{i,\\text{in}} + t_i + t_{i,\\text{out}} = total time to complete all tasks done on resource \\ell (where J_\\ell is the set of indexes of tasks done on resource \\ell)\nPotential bottlenecks:\n\ninput (data) are not ready/available when a worker need them to complete a task (the worker have to wait)\noutput (results) cannot be written when a worker complete a task (the worker have to wait)\n\nOverhead on memory access\n\nconcurrent access to a memory space when reading input and/or when writing output\nconcurrent data transfer from or to memory (the “pipe” are jammed)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introduction to parallel computing</span>"
    ]
  },
  {
    "objectID": "Courses/02_Parallel-intro.html#illustration-1-overhead-for-io-access",
    "href": "Courses/02_Parallel-intro.html#illustration-1-overhead-for-io-access",
    "title": "3  Introduction to parallel computing",
    "section": "4.16 Illustration 1: overhead for I/O access",
    "text": "4.16 Illustration 1: overhead for I/O access\n\n\n\na task\n\nsimulate a vector of 10 values\ncompute the mean\n\nObjective: run 10000 tasks\nResources: 8 computing units\nNumber of workers: 1, 2, 4, 6, 8\n\n\n\n\n10 repetitions in each configurations",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introduction to parallel computing</span>"
    ]
  },
  {
    "objectID": "Courses/02_Parallel-intro.html#illustration-2-overhead-for-io-access",
    "href": "Courses/02_Parallel-intro.html#illustration-2-overhead-for-io-access",
    "title": "3  Introduction to parallel computing",
    "section": "4.17 Illustration 2: overhead for I/O access",
    "text": "4.17 Illustration 2: overhead for I/O access\n\n\n\na task = “compute the sum of a given row in a matrix”\nObjective: compute all row-wise sums for a 10000 \\times 1000 matrix (i.e. 10000 tasks)\nResources: 8 computing units\nNumber of workers: 1, 2, 4, 6, 8\n\n\n\n\n20 repetitions in each configurations",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introduction to parallel computing</span>"
    ]
  },
  {
    "objectID": "Courses/02_Parallel-intro.html#the-vocabulary-of-parallel-computing",
    "href": "Courses/02_Parallel-intro.html#the-vocabulary-of-parallel-computing",
    "title": "3  Introduction to parallel computing",
    "section": "4.18 The vocabulary of parallel computing",
    "text": "4.18 The vocabulary of parallel computing\n\ntasks = a command or a group of commands\nworker = a program or a sub-program (like a thread or a sub-process) → Software\nworking resources = processing units → Hardware\ninput = data\noutput = result\nstorage = memory\n\nAttention: “worker” may sometimes refer to a working resource in the literature",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introduction to parallel computing</span>"
    ]
  },
  {
    "objectID": "Courses/02_Parallel-intro.html#task-synchronization",
    "href": "Courses/02_Parallel-intro.html#task-synchronization",
    "title": "3  Introduction to parallel computing",
    "section": "4.19 Task synchronization",
    "text": "4.19 Task synchronization\n\nSometimes tasks cannot be done in parallel\n\nSpecific case: output of task i_1 is input of task i_2\nNeed: wait for task i_1 before task i_2 starts\n\n\n\n\nExample 1:\n# task 1: matrix product\nC = A @ B\n# task 2: colwise sum over matrix C\nnp.sum(C,axis=0)\n\nExample 2:\n\ntask 1: train a predictive model\ntask 2: use the trained model to predict new labels",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introduction to parallel computing</span>"
    ]
  },
  {
    "objectID": "Courses/02_Parallel-intro.html#trend-over-50years",
    "href": "Courses/02_Parallel-intro.html#trend-over-50years",
    "title": "3  Introduction to parallel computing",
    "section": "5.1 Trend over ~50years",
    "text": "5.1 Trend over ~50years\n\n\nMoore’s Law (doubling the transistor counts every two years) is live\nSingle thread performance hit a wall in 2000s\nAlong with typical power usage and frequency\nNumber of logical cores is doubling every ~3 years since mid-2000\n\n\n\n\nOriginal data up to the year 2010 collected and plotted by M. Horowitz, F. Labonte, O. Shacham, K. Olukotun, L. Hammond, and C. Batten New plot and data collected for 2010-2021 by K. Rupp\n\n\n\n\nGithub repo for data",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introduction to parallel computing</span>"
    ]
  },
  {
    "objectID": "Courses/02_Parallel-intro.html#computing-units",
    "href": "Courses/02_Parallel-intro.html#computing-units",
    "title": "3  Introduction to parallel computing",
    "section": "5.2 Computing units",
    "text": "5.2 Computing units\n\n\nCPU :\n\n4/8/16+ execution cores (depending on context, laptop, desktop, server)\nHyperthreading (Intel) or SMT (AMD), x2\nVector units (multiple instructions processed on a vector of data)\n\nGPU computing : 100/1000 “simple” cores per card",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introduction to parallel computing</span>"
    ]
  },
  {
    "objectID": "Courses/02_Parallel-intro.html#the-reality",
    "href": "Courses/02_Parallel-intro.html#the-reality",
    "title": "3  Introduction to parallel computing",
    "section": "5.3 The reality",
    "text": "5.3 The reality\n\n\nA serial application only accesses 0.8% of the processing power of a 16-core CPU.\n\n\n\n0.08\\% = \\frac{1}{16 * 2 (cores + hyperthreading) * \\frac{256 (bitwide vector unit}{64(bit double)} = 128}",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introduction to parallel computing</span>"
    ]
  },
  {
    "objectID": "Courses/02_Parallel-intro.html#faster-for-less-development",
    "href": "Courses/02_Parallel-intro.html#faster-for-less-development",
    "title": "3  Introduction to parallel computing",
    "section": "6.1 Faster for less development",
    "text": "6.1 Faster for less development\n\\frac{S_{up}}{T_{par}} \\gg \\frac{S_{up}}{T_{seq}}\nRatio of speedup improvment S_{up} over time of development (T_{seq|par}) comparison.\nFrom a development time perspective, return on investment (speedup) is often several magnitudes of order better than pure “serial/sequential” improvment.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introduction to parallel computing</span>"
    ]
  },
  {
    "objectID": "Courses/02_Parallel-intro.html#scaling",
    "href": "Courses/02_Parallel-intro.html#scaling",
    "title": "3  Introduction to parallel computing",
    "section": "6.2 Scaling",
    "text": "6.2 Scaling\nSimple “divide and conquer” strategies in parallel programming allow to handle data with previously almost untractable sizes and scale before.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introduction to parallel computing</span>"
    ]
  },
  {
    "objectID": "Courses/02_Parallel-intro.html#energy-efficiency",
    "href": "Courses/02_Parallel-intro.html#energy-efficiency",
    "title": "3  Introduction to parallel computing",
    "section": "6.3 Energy efficiency",
    "text": "6.3 Energy efficiency\n\n\n\n\n\n\nNote\n\n\n\nThis is a huge one, in the present context 😬\n\n\nDifficult to estimate but the Thermal Design Power (TDP), given by hardware manufacturers, is a good rule of thumb. Just factor the number of units, and usual proportionality rules.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introduction to parallel computing</span>"
    ]
  },
  {
    "objectID": "Courses/02_Parallel-intro.html#energy-efficiency-a-bunch-of-cpus",
    "href": "Courses/02_Parallel-intro.html#energy-efficiency-a-bunch-of-cpus",
    "title": "3  Introduction to parallel computing",
    "section": "6.4 Energy efficiency, a bunch of CPUs",
    "text": "6.4 Energy efficiency, a bunch of CPUs\nExample of “standard” use : 20 16-core Intel Xeon E5-4660 which is 120~W of TDP\nP = (20~Processors) * (120~W/~Processors) * (24~hours) = 57.60~kWhrs",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introduction to parallel computing</span>"
    ]
  },
  {
    "objectID": "Courses/02_Parallel-intro.html#energy-efficiency-just-a-few-big-gpus",
    "href": "Courses/02_Parallel-intro.html#energy-efficiency-just-a-few-big-gpus",
    "title": "3  Introduction to parallel computing",
    "section": "6.5 Energy efficiency, just a few (big) GPUs",
    "text": "6.5 Energy efficiency, just a few (big) GPUs\nA Tesla V100 GPU is of 300~W of TDP. Let’s use 4 of them.\nP = (4~GPUs) * (300~W/~GPUs) * (24~hours) = 28.80~kWhrs\n\\Longrightarrow half of the power use",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introduction to parallel computing</span>"
    ]
  },
  {
    "objectID": "Courses/02_Parallel-intro.html#terms-and-definitions",
    "href": "Courses/02_Parallel-intro.html#terms-and-definitions",
    "title": "3  Introduction to parallel computing",
    "section": "7.1 Terms and definitions",
    "text": "7.1 Terms and definitions\n\nSpeedup S_{up}(N): ratio of the time of execution in serial and parallel mode\nNumber of computing units N\nP (resp. S) is the parallel (resp. serial) fraction of the time spent in the parallel (resp. serial) part of the program (P+S=1).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introduction to parallel computing</span>"
    ]
  },
  {
    "objectID": "Courses/02_Parallel-intro.html#asymptote-of-parallel-computing-amdahls-law",
    "href": "Courses/02_Parallel-intro.html#asymptote-of-parallel-computing-amdahls-law",
    "title": "3  Introduction to parallel computing",
    "section": "7.2 Asymptote of parallel computing : Amdahl’s Law",
    "text": "7.2 Asymptote of parallel computing : Amdahl’s Law\nThere P is the fraction of the time spent in the parallel part of the program in a sequential execution.\nS_{up}(N) \\le \\frac{1}{S+\\frac{P}{N}}",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introduction to parallel computing</span>"
    ]
  },
  {
    "objectID": "Courses/02_Parallel-intro.html#asymptote-of-parallel-computing-amdahls-law-graphic",
    "href": "Courses/02_Parallel-intro.html#asymptote-of-parallel-computing-amdahls-law-graphic",
    "title": "3  Introduction to parallel computing",
    "section": "7.3 Asymptote of parallel computing : Amdahl’s Law, Graphic",
    "text": "7.3 Asymptote of parallel computing : Amdahl’s Law, Graphic\n\n\nIdeal speedup : 100% of the code parallelized; 90%, 75%, and 50% : limited by the fractions of code that remain serial. (Robey and Zamora 2021)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introduction to parallel computing</span>"
    ]
  },
  {
    "objectID": "Courses/02_Parallel-intro.html#more-with-almost-less-the-pump-it-up-approach",
    "href": "Courses/02_Parallel-intro.html#more-with-almost-less-the-pump-it-up-approach",
    "title": "3  Introduction to parallel computing",
    "section": "7.4 More with (almost) less : the pump it up approach",
    "text": "7.4 More with (almost) less : the pump it up approach\nGustafson’s law\nThere now, P is the fraction of the time spent in the parallel part of the program in a parallel execution.\n\n\n\n\nWhen the size of the problem grows up proportionnaly to the number of computing units.\nS_{up}(N) \\le N - S*(N-1)\nwhere N is the number of computing units and S the serial fraction as before.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introduction to parallel computing</span>"
    ]
  },
  {
    "objectID": "Courses/02_Parallel-intro.html#more-with-almost-less-graphic",
    "href": "Courses/02_Parallel-intro.html#more-with-almost-less-graphic",
    "title": "3  Introduction to parallel computing",
    "section": "7.5 More with (almost) less : graphic",
    "text": "7.5 More with (almost) less : graphic\n\n\nLinear growth with the number of processor (and data size too)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introduction to parallel computing</span>"
    ]
  },
  {
    "objectID": "Courses/02_Parallel-intro.html#strong-vs-weak-scaling-definitions",
    "href": "Courses/02_Parallel-intro.html#strong-vs-weak-scaling-definitions",
    "title": "3  Introduction to parallel computing",
    "section": "7.6 Strong vs Weak Scaling, definitions",
    "text": "7.6 Strong vs Weak Scaling, definitions\n\n\nStrong Scaling\n\nStrong scaling represents the time to solution with respect to the number of processors for a fixed total size.\n\n\n\\Rightarrow Amdahl’s law\n\nWeak Scaling\n\nWeak scaling represents the time to solution with respect to the number of processors for a fixed-sized problem per processor.\n\n\n\\Rightarrow Gustafson’s law",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introduction to parallel computing</span>"
    ]
  },
  {
    "objectID": "Courses/02_Parallel-intro.html#strong-vs-weak-scaling-schemas",
    "href": "Courses/02_Parallel-intro.html#strong-vs-weak-scaling-schemas",
    "title": "3  Introduction to parallel computing",
    "section": "7.7 Strong vs Weak Scaling, schemas",
    "text": "7.7 Strong vs Weak Scaling, schemas",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introduction to parallel computing</span>"
    ]
  },
  {
    "objectID": "Courses/02_Parallel-intro.html#flynns-taxonomy",
    "href": "Courses/02_Parallel-intro.html#flynns-taxonomy",
    "title": "3  Introduction to parallel computing",
    "section": "8.1 Flynn’s taxonomy",
    "text": "8.1 Flynn’s taxonomy\n\n\n\n\nSimple Instruction\nMultiple Instructions\n\n\n\n\nSimple Data\n\n\n\n\nMultiple Data",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introduction to parallel computing</span>"
    ]
  },
  {
    "objectID": "Courses/02_Parallel-intro.html#a-different-approach",
    "href": "Courses/02_Parallel-intro.html#a-different-approach",
    "title": "3  Introduction to parallel computing",
    "section": "8.2 A different approach",
    "text": "8.2 A different approach\n\n\n\nParallelism level\nHardware\nSoftware\nParallelism extraction\n\n\n\n\nInstruction\nSIMD (or VLIW)\nIntrinsics\nCompiler\n\n\nThread\nMulti-core RTOS\nLibrary or language extension\nPartitioning/Scheduling (dependency control)\n\n\nTask\nMulti-core (w/o RTOS)\nProcesses (OS level)\nPartitioning/Scheduling",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introduction to parallel computing</span>"
    ]
  },
  {
    "objectID": "Courses/02_Parallel-intro.html#multi-processing-vs-multi-threading",
    "href": "Courses/02_Parallel-intro.html#multi-processing-vs-multi-threading",
    "title": "3  Introduction to parallel computing",
    "section": "8.3 Multi-processing vs Multi-threading",
    "text": "8.3 Multi-processing vs Multi-threading\n\n\n\n\n\nMulti-Processing\n\n\n\n\n\n\n\nMulti-Threading\n\n\n\n\n\n\n\n\n\n\nMulti-processing\nMulti-threading\n\n\n\n\nMemory\nExclusive\nShared\n\n\nCommunication\nInter-process\nAt caller site\n\n\nCreation overhead\nHeavy\nMinimal\n\n\nConcurrency\nAt OS level\nLibrary/language",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introduction to parallel computing</span>"
    ]
  },
  {
    "objectID": "Courses/02_Parallel-intro.html#footnotes",
    "href": "Courses/02_Parallel-intro.html#footnotes",
    "title": "3  Introduction to parallel computing",
    "section": "",
    "text": "i.e. a set of tools/machines used by a worker to complete a task↩︎\noverhead on resource access↩︎",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introduction to parallel computing</span>"
    ]
  },
  {
    "objectID": "Courses/03_Asynchronous.html",
    "href": "Courses/03_Asynchronous.html",
    "title": "4  Asynchronous Programming with Python",
    "section": "",
    "text": "5 Asynchronous, Basics",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Asynchronous Programming with Python</span>"
    ]
  },
  {
    "objectID": "Courses/03_Asynchronous.html#what-is-asynchronous-programming",
    "href": "Courses/03_Asynchronous.html#what-is-asynchronous-programming",
    "title": "4  Asynchronous Programming with Python",
    "section": "5.1 What is Asynchronous Programming?",
    "text": "5.1 What is Asynchronous Programming?\n\nAsynchronous programming is a programming paradigm that allows the program to continue executing other tasks before the current task is finished.\nIt is a way to achieve concurrency in a program.\n\n\\Rightarrow it is an abstraction over concurrency, it does not necessarily mean that the program is executed in parallel.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Asynchronous Programming with Python</span>"
    ]
  },
  {
    "objectID": "Courses/03_Asynchronous.html#io-bound-vs.-cpu-bound",
    "href": "Courses/03_Asynchronous.html#io-bound-vs.-cpu-bound",
    "title": "4  Asynchronous Programming with Python",
    "section": "5.2 I/O Bound vs. CPU Bound",
    "text": "5.2 I/O Bound vs. CPU Bound\nimport requests\n \n1response = requests.get('https://www.example.com')\n \nitems = response.headers.items()\n \n2headers = [f'{key}: {header}' for key, header in items]\n \n3formatted_headers = '\\n'.join(headers)\n \nwith open('headers.txt', 'w') as file:\n4    file.write(formatted_headers)\n\n1\n\nI/O-bound web request\n\n2\n\nCPU-bound response processing\n\n3\n\nCPU-bound string concatenation\n\n4\n\nI/O-bound write to disk",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Asynchronous Programming with Python</span>"
    ]
  },
  {
    "objectID": "Courses/03_Asynchronous.html#concurrency-vs.-parallelism",
    "href": "Courses/03_Asynchronous.html#concurrency-vs.-parallelism",
    "title": "4  Asynchronous Programming with Python",
    "section": "6.1 Concurrency vs. Parallelism",
    "text": "6.1 Concurrency vs. Parallelism\n\n\nOne baker and two cakes to prepare.\n\nCan preheat the oven while preparing the first cake.\nCan start the second cake while the first one is in the oven.\n\n\\Rightarrow Switching between tasks is concurrency (or concurrent behavior).\n\nTwo bakers and two cakes to prepare.\n\nCan prepare both cakes at the same time.\n\n\\Rightarrow Doing multiple tasks in parallel is parallelism (or parallel behavior).\n\n\n\n\nWith concurrency, we have multiple tasks happening at the same time, but only one we’re actively doing at a given point in time. With parallelism, we have multiple tasks happening and are actively doing more than one simultaneously.\n\n\n\n\nFrom Fowler (2022)\n\n\n\nWith concurrency, we switch between running two applications. With parallelism, we actively run two applications simultaneously.\n\n\n\n\nFrom Fowler (2022)\n\n\nConcurrency is about multiple independent tasks that can happen.\nParallelism is concurrency AND simultaneous execution.\n\nWhile parallelism implies concurrency, concurrency does not always imply parallelism.\n\\Rightarrow Concurrency is a broader concept than parallelism.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Asynchronous Programming with Python</span>"
    ]
  },
  {
    "objectID": "Courses/03_Asynchronous.html#multitasking",
    "href": "Courses/03_Asynchronous.html#multitasking",
    "title": "4  Asynchronous Programming with Python",
    "section": "6.2 Multitasking",
    "text": "6.2 Multitasking\n\n\n\n6.2.1 Preemptive multitasking\n\nThe operating system decides when to switch between tasks.\nThe tasks are not aware of each other.\n\n\n\n\n6.2.2 Cooperative multitasking\n\nIn this model we have to explicitly to decide when to switch between tasks.\nThe tasks are aware of each other.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Asynchronous Programming with Python</span>"
    ]
  },
  {
    "objectID": "Courses/03_Asynchronous.html#benefits-of-cooperative-multitasking",
    "href": "Courses/03_Asynchronous.html#benefits-of-cooperative-multitasking",
    "title": "4  Asynchronous Programming with Python",
    "section": "6.3 Benefits of cooperative multitasking",
    "text": "6.3 Benefits of cooperative multitasking\n\nLess overhead than preemptive multitasking.\nGranular/optimal control over when to switch between tasks.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Asynchronous Programming with Python</span>"
    ]
  },
  {
    "objectID": "Courses/03_Asynchronous.html#multi-processing-vs-multi-threading",
    "href": "Courses/03_Asynchronous.html#multi-processing-vs-multi-threading",
    "title": "4  Asynchronous Programming with Python",
    "section": "7.1 Multi-processing vs Multi-threading",
    "text": "7.1 Multi-processing vs Multi-threading\n\n\n\n\n\nMulti-Processing\n\n\n\n\n\n\n\nMulti-Threading",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Asynchronous Programming with Python</span>"
    ]
  },
  {
    "objectID": "Courses/03_Asynchronous.html#processes-and-threads",
    "href": "Courses/03_Asynchronous.html#processes-and-threads",
    "title": "4  Asynchronous Programming with Python",
    "section": "7.2 Processes and threads",
    "text": "7.2 Processes and threads\n\nimport os\nimport threading\n \nprint(f'Python process running with process id: {os.getpid()}')\ntotal_threads = threading.active_count()\nthread_name = threading.current_thread().name\n \nprint(f'Python is currently running {total_threads} thread(s)')\nprint(f'The current thread is {thread_name}')\n\nPython process running with process id: 89280\nPython is currently running 8 thread(s)\nThe current thread is MainThread",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Asynchronous Programming with Python</span>"
    ]
  },
  {
    "objectID": "Courses/03_Asynchronous.html#creating-processes",
    "href": "Courses/03_Asynchronous.html#creating-processes",
    "title": "4  Asynchronous Programming with Python",
    "section": "7.3 Creating processes",
    "text": "7.3 Creating processes\n\nimport multiprocessing\nimport os\n \n \ndef hello_from_process():\n    print(f'Hello from child process {os.getpid()}!')\nif __name__ == '__main__':\n    hello_process = multiprocessing.Process(target=hello_from_process)\n    hello_process.start()\n \n    print(f'Hello from parent process {os.getpid()}')\n \n    hello_process.join()\n\nHello from parent process 89280\nHello from child process 89329!",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Asynchronous Programming with Python</span>"
    ]
  },
  {
    "objectID": "Courses/03_Asynchronous.html#creating-threads",
    "href": "Courses/03_Asynchronous.html#creating-threads",
    "title": "4  Asynchronous Programming with Python",
    "section": "7.4 Creating threads",
    "text": "7.4 Creating threads\n\nimport threading\n \n \ndef hello_from_thread():\n    print(f'Hello from thread {threading.current_thread()}!')\n \n \nhello_thread = threading.Thread(target=hello_from_thread)\nhello_thread.start()\n \ntotal_threads = threading.active_count()\nthread_name = threading.current_thread().name\n \nprint(f'Python is currently running {total_threads} thread(s)')\nprint(f'The current thread is {thread_name}')\n \nhello_thread.join()\n\nHello from thread &lt;Thread(Thread-6 (hello_from_thread), started 6226817024)&gt;!Python is currently running 9 thread(s)\nThe current thread is MainThread",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Asynchronous Programming with Python</span>"
    ]
  },
  {
    "objectID": "Courses/03_Asynchronous.html#what-about-python",
    "href": "Courses/03_Asynchronous.html#what-about-python",
    "title": "4  Asynchronous Programming with Python",
    "section": "8.1 What about Python?",
    "text": "8.1 What about Python?\n\n\nDesigned for sequential and single-core architecture from the beginning\nEverything is interpreted\nAll dynamic (no static types)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Asynchronous Programming with Python</span>"
    ]
  },
  {
    "objectID": "Courses/03_Asynchronous.html#the-gil",
    "href": "Courses/03_Asynchronous.html#the-gil",
    "title": "4  Asynchronous Programming with Python",
    "section": "8.2 The GIL",
    "text": "8.2 The GIL\nAka Global Interpreter Lock\n. . .\n\nThe GIL allows thread usage, you can create threads and launch them: YES!\n\n. . .\n\nbut…\n\n. . .\n\nOnly ONE thread can actually execute code at python level..",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Asynchronous Programming with Python</span>"
    ]
  },
  {
    "objectID": "Courses/03_Asynchronous.html#multi-threaded-parallel-execution",
    "href": "Courses/03_Asynchronous.html#multi-threaded-parallel-execution",
    "title": "4  Asynchronous Programming with Python",
    "section": "8.3 Multi-threaded != Parallel execution",
    "text": "8.3 Multi-threaded != Parallel execution\nMulti-threading doesn’t guarantee parallel execution…\n\n\n\n\n\n\\Longrightarrow Python seems to have started off with the wrong foot by a long way…",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Asynchronous Programming with Python</span>"
    ]
  },
  {
    "objectID": "Courses/03_Asynchronous.html#high-performance-python",
    "href": "Courses/03_Asynchronous.html#high-performance-python",
    "title": "4  Asynchronous Programming with Python",
    "section": "8.4 High performance Python 😬",
    "text": "8.4 High performance Python 😬\n\n\n\n\n\n\nBut wait!\n\n\nActually we can run (real) parallel programs with the multiprocessing package.\n\\Rightarrow But this is an “OS level” multiprocessing, with associated huge overhead (relatively)\nPython actually releases the GIL when executing everything that is not Python code (e.g. C/C++ extensions and libraries)\n\\Rightarrow It means we can parallelize our code by using I/O bound and CPU bound libraries that release the GIL (this is the case for most of them)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Asynchronous Programming with Python</span>"
    ]
  },
  {
    "objectID": "Courses/03_Asynchronous.html#socket",
    "href": "Courses/03_Asynchronous.html#socket",
    "title": "4  Asynchronous Programming with Python",
    "section": "9.1 Socket",
    "text": "9.1 Socket\n\n\nWriting bytes to a socket and reading bytes from a socket\n\n\n\n\nFrom Fowler (2022)\n\n\nThis a mailbox metaphor\nBy default, the socket is blocking, i.e. the program will wait until the socket is ready to be read or written.\nWe can make the socket non-blocking, i.e. the program will not wait for the socket to be ready to be read or written. \\Rightarrow Later on, the OS will tell us we received byte and we deal with it.\n\n\n\n\n\n\n\nMaking a non-blocking I/O request returns immediately\ntells the O/S to watch sockets for data \\Rightarrow This allows execute_other_code() to run right away instead of waiting for the I/O requests to finish\nLater, we can be alerted when I/O is complete and process the response.\n\n\n\n\n\nFrom Fowler (2022)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Asynchronous Programming with Python</span>"
    ]
  },
  {
    "objectID": "Courses/03_Asynchronous.html#event-loop",
    "href": "Courses/03_Asynchronous.html#event-loop",
    "title": "4  Asynchronous Programming with Python",
    "section": "9.2 Event Loop",
    "text": "9.2 Event Loop\n\n\nfrom collections import deque\n \nmessages = deque()\n \nwhile True:\n    if messages:\n        message = messages.pop()\n        process_message(message)\n\n\n\nThe event loop is a loop that runs forever.\nIt checks if there are any messages to process.\nIf there are, it processes them.\nIf there are not, it waits for messages to arrive.\n\n\n\n\n\\Rightarrow In asyncio, the event loop is queue of tasks instead of messages, Tasks are wrapped coroutines.\n\ndef make_request():\n    cpu_bound_setup()\n    io_bound_web_request()\n    cpu_bound_postprocess()\n \ntask_one = make_request()\ntask_two = make_request()\ntask_three = make_request()",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Asynchronous Programming with Python</span>"
    ]
  },
  {
    "objectID": "Courses/03_Asynchronous.html#what-is-it",
    "href": "Courses/03_Asynchronous.html#what-is-it",
    "title": "4  Asynchronous Programming with Python",
    "section": "10.1 What is it?",
    "text": "10.1 What is it?\n\nasync def coroutine_add_one(number: int) -&gt; int:\n    return number + 1\n \ndef add_one(number: int) -&gt; int:\n    return number + 1\n \n1function_result = add_one(1)\n2coroutine_result = coroutine_add_one(1)\n \nprint(f'Function result is {function_result}\\n\\\n    and the type is {type(function_result)}')\nprint(f'Coroutine result is {coroutine_result}\\n\\\n    and the type is {type(coroutine_result)}')\n\n\n1\n\nfunction call, is executed immediately.\n\n2\n\ncoroutine call, is not executed at all, but returns a coroutine object.\n\n\n\n\nFunction result is 2\n    and the type is &lt;class 'int'&gt;\nCoroutine result is &lt;coroutine object coroutine_add_one at 0x121356440&gt;\n    and the type is &lt;class 'coroutine'&gt;\n\n\n\nFrom Fowler (2022)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Asynchronous Programming with Python</span>"
    ]
  },
  {
    "objectID": "Courses/03_Asynchronous.html#how-to-execute-a-coroutine",
    "href": "Courses/03_Asynchronous.html#how-to-execute-a-coroutine",
    "title": "4  Asynchronous Programming with Python",
    "section": "10.2 How to execute a coroutine?",
    "text": "10.2 How to execute a coroutine?\nYou need an event loop.\nimport asyncio\n \nasync def coroutine_add_one(number: int) -&gt; int:\n    return number + 1\n \n1result = asyncio.run(coroutine_add_one(1))\n\nprint(result)\n\n1\n\nThis launches the event loop, executes the coroutine, and returns the result.\n\n\n\n\n\n\n\n\nWarning\n\n\n\nThis code will not work in a Jupyter notebook, because the event loop is already running (by Jupyter itself). So you just have to replace the line 4 by:\nresult = await coroutine_add_one(1)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Asynchronous Programming with Python</span>"
    ]
  },
  {
    "objectID": "Courses/03_Asynchronous.html#await-keyword",
    "href": "Courses/03_Asynchronous.html#await-keyword",
    "title": "4  Asynchronous Programming with Python",
    "section": "10.3 await keyword",
    "text": "10.3 await keyword\n\nimport asyncio\n \nasync def add_one(number: int) -&gt; int:\n    return number + 1\n \n \nasync def main() -&gt; None:\n1    one_plus_one = await add_one(1)\n2    two_plus_one = await add_one(2)\n    print(one_plus_one)\n    print(two_plus_one)\n \n3await main()\n\n\n1\n\nPause, and wait for the result of add_one(1).\n\n2\n\nPause, and wait for the result of add_one(2).\n\n3\n\nPause, and wait for the result of main(). (outside of a Jupyter notebook, you have to launch the event loop somewhere, like asyncio.run(main()) instead of await main())\n\n\n\n\n2\n3\n\n\n\n\nFrom Fowler (2022)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Asynchronous Programming with Python</span>"
    ]
  },
  {
    "objectID": "Courses/03_Asynchronous.html#simulating-the-real-thing-with-asyncio.sleep",
    "href": "Courses/03_Asynchronous.html#simulating-the-real-thing-with-asyncio.sleep",
    "title": "4  Asynchronous Programming with Python",
    "section": "10.4 Simulating the real thing with asyncio.sleep",
    "text": "10.4 Simulating the real thing with asyncio.sleep\n\nimport asyncio\n \nasync def hello_world_message() -&gt; str:\n1    await asyncio.sleep(1)\n    return 'Hello World!'\n \nasync def main() -&gt; None:\n2    message = await hello_world_message()\n    print(message)\n \nawait main()\n\n\n1\n\nPause hello_world_message for 1 second.\n\n2\n\nPause main until hello_world_message is finished.\n\n\n\n\nHello World!",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Asynchronous Programming with Python</span>"
    ]
  },
  {
    "objectID": "Courses/03_Asynchronous.html#utility-function-delayseconds",
    "href": "Courses/03_Asynchronous.html#utility-function-delayseconds",
    "title": "4  Asynchronous Programming with Python",
    "section": "10.5 Utility function delay(seconds)",
    "text": "10.5 Utility function delay(seconds)\n\nimport asyncio\n \n \n1async def delay(delay_seconds: int) -&gt; int:\n2    print(f'sleeping for {delay_seconds} second(s)')\n    await asyncio.sleep(delay_seconds)\n    print(f'finished sleeping for {delay_seconds} second(s)')\n3    return delay_seconds\n\n\n1\n\nTakes an integer of the duration in seconds that we’d like the function to sleep.\n\n2\n\nPrints when sleep begins and ends.\n\n3\n\nReturns that integer to the caller once it has finished sleeping.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Asynchronous Programming with Python</span>"
    ]
  },
  {
    "objectID": "Courses/03_Asynchronous.html#running-two-coroutines",
    "href": "Courses/03_Asynchronous.html#running-two-coroutines",
    "title": "4  Asynchronous Programming with Python",
    "section": "10.6 Running two coroutines",
    "text": "10.6 Running two coroutines\n\nimport asyncio\n \nasync def add_one(number: int) -&gt; int:\n    return number + 1\n \nasync def hello_world_message() -&gt; str:\n    await delay(1)\n    return 'Hello World!'\n \nasync def main() -&gt; None:\n1    message = await hello_world_message()\n2    one_plus_one = await add_one(1)\n    print(one_plus_one)\n    print(message)\n \nawait main()\n\n\n1\n\nPause main until hello_world_message is finished.\n\n2\n\nPause main until add_one is finished.\n\n\n\n\nsleeping for 1 second(s)\nfinished sleeping for 1 second(s)\n2\nHello World!\n\n\n\n\nFrom Fowler (2022)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Asynchronous Programming with Python</span>"
    ]
  },
  {
    "objectID": "Courses/03_Asynchronous.html#what-to-do-next",
    "href": "Courses/03_Asynchronous.html#what-to-do-next",
    "title": "4  Asynchronous Programming with Python",
    "section": "10.7 What to do next?",
    "text": "10.7 What to do next?\nMoving away from sequential execution and run add_one and hello_world_message concurrently.\nFor that we need…",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Asynchronous Programming with Python</span>"
    ]
  },
  {
    "objectID": "Courses/03_Asynchronous.html#creating-tasks",
    "href": "Courses/03_Asynchronous.html#creating-tasks",
    "title": "4  Asynchronous Programming with Python",
    "section": "11.1 Creating tasks",
    "text": "11.1 Creating tasks\n\nimport asyncio\n\nasync def main():\n    sleep_for_three = asyncio.create_task(delay(3))\n    print(type(sleep_for_three))\n    result = await sleep_for_three\n    print(result)\n \nawait main()\n\n&lt;class '_asyncio.Task'&gt;\nsleeping for 3 second(s)\nfinished sleeping for 3 second(s)\n3\n\n\n\nthe coroutine is scheduled to run in the event loop as soon as possible.\nbefore, it was just run at the await statement (pausing the caller).",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Asynchronous Programming with Python</span>"
    ]
  },
  {
    "objectID": "Courses/03_Asynchronous.html#running-tasks-concurrently",
    "href": "Courses/03_Asynchronous.html#running-tasks-concurrently",
    "title": "4  Asynchronous Programming with Python",
    "section": "11.2 Running tasks concurrently",
    "text": "11.2 Running tasks concurrently\n\nimport asyncio\n \nasync def main():\n    sleep_for_three = \\\n        asyncio.create_task(delay(3))\n    sleep_again = \\\n        asyncio.create_task(delay(3))\n    sleep_once_more = \\\n        asyncio.create_task(delay(3))\n \n    await sleep_for_three\n    await sleep_again\n    await sleep_once_more\n\nawait main()\n\nsleeping for 3 second(s)\nsleeping for 3 second(s)\nsleeping for 3 second(s)\nfinished sleeping for 3 second(s)\nfinished sleeping for 3 second(s)\nfinished sleeping for 3 second(s)\n\n\n\n\nFrom Fowler (2022)\n\n\nimport asyncio\n \nasync def hello_every_second():\n    for i in range(2):\n        await asyncio.sleep(1)\n        print(\"I'm running other code while I'm waiting!\")\n \nasync def main():\n    first_delay = asyncio.create_task(delay(3))\n    second_delay = asyncio.create_task(delay(3))\n    await hello_every_second()\n    await first_delay\n    await second_delay\n\nawait main()\n\nsleeping for 3 second(s)\nsleeping for 3 second(s)\nI'm running other code while I'm waiting!\nI'm running other code while I'm waiting!\nfinished sleeping for 3 second(s)\nfinished sleeping for 3 second(s)\n\n\n\n\nFrom Fowler (2022)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Asynchronous Programming with Python</span>"
    ]
  },
  {
    "objectID": "Courses/03_Asynchronous.html#canceling-tasks",
    "href": "Courses/03_Asynchronous.html#canceling-tasks",
    "title": "4  Asynchronous Programming with Python",
    "section": "11.3 Canceling tasks",
    "text": "11.3 Canceling tasks\n\nimport asyncio\nfrom asyncio import CancelledError\n\nasync def main():\n    long_task = asyncio.create_task(delay(10))\n \n    seconds_elapsed = 0\n \n    while not long_task.done():\n        print('Task not finished, checking again in a second.')\n        await asyncio.sleep(1)\n        seconds_elapsed = seconds_elapsed + 1\n        if seconds_elapsed == 5:\n            long_task.cancel()\n \n    try:\n        await long_task\n    except CancelledError:\n        print('Our task was cancelled')\n \nawait main()\n\nTask not finished, checking again in a second.\nsleeping for 10 second(s)\nTask not finished, checking again in a second.\nTask not finished, checking again in a second.\nTask not finished, checking again in a second.\nTask not finished, checking again in a second.\nTask not finished, checking again in a second.\nOur task was cancelled",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Asynchronous Programming with Python</span>"
    ]
  },
  {
    "objectID": "Courses/03_Asynchronous.html#setting-a-timeout",
    "href": "Courses/03_Asynchronous.html#setting-a-timeout",
    "title": "4  Asynchronous Programming with Python",
    "section": "11.4 Setting a timeout",
    "text": "11.4 Setting a timeout\n\nimport asyncio\n\nasync def main():\n    delay_task = asyncio.create_task(delay(2))\n    try:\n        result = await asyncio.wait_for(delay_task, timeout=1)\n        print(result)\n    except asyncio.exceptions.TimeoutError:\n        print('Got a timeout!')\n        print(f'Was the task cancelled? {delay_task.cancelled()}')\n \nawait main()\n\nsleeping for 2 second(s)\nGot a timeout!\nWas the task cancelled? True",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Asynchronous Programming with Python</span>"
    ]
  },
  {
    "objectID": "Courses/03_Asynchronous.html#introducing-futures",
    "href": "Courses/03_Asynchronous.html#introducing-futures",
    "title": "4  Asynchronous Programming with Python",
    "section": "12.1 Introducing futures",
    "text": "12.1 Introducing futures\n\nfrom asyncio import Future\n \nmy_future = Future()\n \nprint(f'Is my_future done? {my_future.done()}')\n \nmy_future.set_result(42)\n \nprint(f'Is my_future done? {my_future.done()}')\nprint(f'What is the result of my_future? {my_future.result()}')\n\nIs my_future done? False\nIs my_future done? True\nWhat is the result of my_future? 42",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Asynchronous Programming with Python</span>"
    ]
  },
  {
    "objectID": "Courses/03_Asynchronous.html#awaiting-futures",
    "href": "Courses/03_Asynchronous.html#awaiting-futures",
    "title": "4  Asynchronous Programming with Python",
    "section": "12.2 Awaiting futures",
    "text": "12.2 Awaiting futures\n\nfrom asyncio import Future\nimport asyncio\n \n \ndef make_request() -&gt; Future:\n    future = Future()\n1    asyncio.create_task(set_future_value(future))\n    return future\n \n \nasync def set_future_value(future) -&gt; None:\n2    await asyncio.sleep(1)\n    future.set_result(42)\n \n \nasync def main():\n    future = make_request()\n    print(f'Is the future done? {future.done()}')\n3    value = await future\n    print(f'Is the future done? {future.done()}')\n    print(value)\n \nawait main()\n\n\n1\n\nCreate a task to asynchronously set the value of the future.\n\n2\n\nWait 1 second before setting the value of the future.\n\n3\n\nPause main until the future’s value is set.\n\n\n\n\nIs the future done? False\nIs the future done? True\n42",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Asynchronous Programming with Python</span>"
    ]
  },
  {
    "objectID": "Courses/03_Asynchronous.html#comparing-tasks-coroutines-futures-and-awaitables",
    "href": "Courses/03_Asynchronous.html#comparing-tasks-coroutines-futures-and-awaitables",
    "title": "4  Asynchronous Programming with Python",
    "section": "12.3 Comparing tasks, coroutines, futures, and awaitables",
    "text": "12.3 Comparing tasks, coroutines, futures, and awaitables\n\n\n\n\n\n\n\nAwaitables\n\nObjects that can be awaited in an async function, including coroutines, tasks, and futures.\n\nCoroutines\n\nSpecial functions that can be paused and resumed later, defined using async def, and can be awaited to allow other coroutines to run.\n\nFutures\n\nRepresent the result of an asynchronous operation, manage its state, and can be awaited to get the result.\n\nTasks\n\nSchedule and run coroutines concurrently, and can be used to cancel or check their status.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Asynchronous Programming with Python</span>"
    ]
  },
  {
    "objectID": "Courses/03_Asynchronous.html#with-a-decorator",
    "href": "Courses/03_Asynchronous.html#with-a-decorator",
    "title": "4  Asynchronous Programming with Python",
    "section": "13.1 With a decorator",
    "text": "13.1 With a decorator\n\n\n\nimport functools\nimport time\nfrom typing import Callable, Any\n \ndef async_timed():\n    def wrapper(func: Callable) -&gt; Callable:\n        @functools.wraps(func)\n        async def wrapped(*args, **kwargs) -&gt; Any:\n            print(f'starting {func} with args {args} {kwargs}')\n            start = time.time()\n            try:\n                return await func(*args, **kwargs)\n            finally:\n                end = time.time()\n                total = end - start\n                print(f'finished {func} in {total:.4f} second(s)')\n \n        return wrapped\n \n    return wrapper\n\n\nOfficial Python documentation for decorators\n\nadd functionality to an existing function\nwithout modifying the function itself\nit intercepts the function call and runs “decorated” code before and after it",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Asynchronous Programming with Python</span>"
    ]
  },
  {
    "objectID": "Courses/03_Asynchronous.html#using-it",
    "href": "Courses/03_Asynchronous.html#using-it",
    "title": "4  Asynchronous Programming with Python",
    "section": "13.2 Using it",
    "text": "13.2 Using it\n\nimport asyncio\n \n@async_timed()\nasync def delay(delay_seconds: int) -&gt; int:\n    print(f'sleeping for {delay_seconds} second(s)')\n    await asyncio.sleep(delay_seconds)\n    print(f'finished sleeping for {delay_seconds} second(s)')\n    return delay_seconds\n \n \n@async_timed()\nasync def main():\n    task_one = asyncio.create_task(delay(2))\n    task_two = asyncio.create_task(delay(3))\n \n    await task_one\n    await task_two\n\nawait main()\n\nstarting &lt;function main at 0x1213b5120&gt; with args () {}\nstarting &lt;function delay at 0x1213b47c0&gt; with args (2,) {}\nsleeping for 2 second(s)\nstarting &lt;function delay at 0x1213b47c0&gt; with args (3,) {}\nsleeping for 3 second(s)\nfinished sleeping for 2 second(s)\nfinished &lt;function delay at 0x1213b47c0&gt; in 2.0011 second(s)\nfinished sleeping for 3 second(s)\nfinished &lt;function delay at 0x1213b47c0&gt; in 3.0013 second(s)\nfinished &lt;function main at 0x1213b5120&gt; in 3.0016 second(s)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Asynchronous Programming with Python</span>"
    ]
  },
  {
    "objectID": "Courses/03_Asynchronous.html#asyncio.gather",
    "href": "Courses/03_Asynchronous.html#asyncio.gather",
    "title": "4  Asynchronous Programming with Python",
    "section": "13.3 asyncio.gather",
    "text": "13.3 asyncio.gather\nasyncio.gather() runs multiple asynchronous operations, wraps a coroutine as a task, and returns a list of results in the same order of awaitables.\n\nimport asyncio\n\n\nasync def call_api(message, result, delay=3):\n    print(message)\n    await asyncio.sleep(delay)\n    return result\n\n\nasync def main():\n    return await asyncio.gather(\n        call_api('Calling API 1 ...', 1),\n        call_api('Calling API 2 ...', 2)\n    )\n\nawait main()\n\nCalling API 1 ...\nCalling API 2 ...\n\n\n[1, 2]\n\n\n\n\n\n\n\n\nCaution\n\n\n\nasyncio.gather takes a tuple of awaitables, not a list of awaitables, but returns a list of results in the same order of awaitables.\nIf you want to pass a list, use the * operator to unpack it as a tuple.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Asynchronous Programming with Python</span>"
    ]
  },
  {
    "objectID": "Courses/03_Asynchronous.html#running-cpu-bound-code",
    "href": "Courses/03_Asynchronous.html#running-cpu-bound-code",
    "title": "4  Asynchronous Programming with Python",
    "section": "14.1 Running CPU-bound code",
    "text": "14.1 Running CPU-bound code\n\nimport asyncio\n\n@async_timed()\nasync def cpu_bound_work() -&gt; int:\n    counter = 0\n    for i in range(100000000):\n        counter = counter + 1\n    return counter\n \n \n@async_timed()\nasync def main():\n    task_one = asyncio.create_task(cpu_bound_work())\n    task_two = asyncio.create_task(cpu_bound_work())\n    await task_one\n    await task_two\n \nawait main()\n\nstarting &lt;function main at 0x1213b5940&gt; with args () {}\nstarting &lt;function cpu_bound_work at 0x1213b5760&gt; with args () {}\nfinished &lt;function cpu_bound_work at 0x1213b5760&gt; in 1.2570 second(s)\nstarting &lt;function cpu_bound_work at 0x1213b5760&gt; with args () {}\nfinished &lt;function cpu_bound_work at 0x1213b5760&gt; in 1.2420 second(s)\nfinished &lt;function main at 0x1213b5940&gt; in 2.4994 second(s)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Asynchronous Programming with Python</span>"
    ]
  },
  {
    "objectID": "Courses/03_Asynchronous.html#running-blocking-apis",
    "href": "Courses/03_Asynchronous.html#running-blocking-apis",
    "title": "4  Asynchronous Programming with Python",
    "section": "14.2 Running blocking APIs",
    "text": "14.2 Running blocking APIs\n\nimport asyncio\nimport requests\n \n@async_timed()\nasync def get_example_status() -&gt; int:\n    return requests.get('http://www.example.com').status_code\n \n \n@async_timed()\nasync def main():\n    task_1 = asyncio.create_task(get_example_status())\n    task_2 = asyncio.create_task(get_example_status())\n    task_3 = asyncio.create_task(get_example_status())\n    await task_1\n    await task_2\n    await task_3\n \nawait main()\n\nstarting &lt;function main at 0x121a04400&gt; with args () {}\nstarting &lt;function get_example_status at 0x1213b56c0&gt; with args () {}\nfinished &lt;function get_example_status at 0x1213b56c0&gt; in 0.1187 second(s)\nstarting &lt;function get_example_status at 0x1213b56c0&gt; with args () {}\nfinished &lt;function get_example_status at 0x1213b56c0&gt; in 0.0649 second(s)\nstarting &lt;function get_example_status at 0x1213b56c0&gt; with args () {}\nfinished &lt;function get_example_status at 0x1213b56c0&gt; in 0.0680 second(s)\nfinished &lt;function main at 0x121a04400&gt; in 0.2522 second(s)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Asynchronous Programming with Python</span>"
    ]
  },
  {
    "objectID": "Courses/03_Asynchronous.html#example-of-blocking-code",
    "href": "Courses/03_Asynchronous.html#example-of-blocking-code",
    "title": "4  Asynchronous Programming with Python",
    "section": "15.1 Example of blocking code",
    "text": "15.1 Example of blocking code\n\nimport requests\n \n \ndef get_status_code(url: str) -&gt; int:\n    response = requests.get(url)\n    return response.status_code\n \n \nurl = 'https://www.example.com'\nprint(get_status_code(url))\nprint(get_status_code(url))\n\n200\n200",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Asynchronous Programming with Python</span>"
    ]
  },
  {
    "objectID": "Courses/03_Asynchronous.html#thread-pool",
    "href": "Courses/03_Asynchronous.html#thread-pool",
    "title": "4  Asynchronous Programming with Python",
    "section": "15.2 Thread Pool",
    "text": "15.2 Thread Pool\n\nimport time\nimport requests\nfrom concurrent.futures import ThreadPoolExecutor\n \n \ndef get_status_code(url: str) -&gt; int:\n    response = requests.get(url)\n    return response.status_code\n \n \nstart = time.time()\n \nwith ThreadPoolExecutor() as pool:\n    urls = ['https://www.example.com' for _ in range(10)]\n    results = pool.map(get_status_code, urls)\n    for result in results:\n        # print(result)\n        pass\n\n \nend = time.time()\n \nprint(f'finished requests in {end - start:.4f} second(s)')\n\nfinished requests in 0.8679 second(s)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Asynchronous Programming with Python</span>"
    ]
  },
  {
    "objectID": "Courses/03_Asynchronous.html#compare-with-sequential-code",
    "href": "Courses/03_Asynchronous.html#compare-with-sequential-code",
    "title": "4  Asynchronous Programming with Python",
    "section": "15.3 Compare with sequential code",
    "text": "15.3 Compare with sequential code\n\nstart = time.time()\n \nurls = ['https://www.example.com' for _ in range(10)]\n \nfor url in urls:\n    result = get_status_code(url)\n    # print(result)\n \nend = time.time()\n \nprint(f'finished requests in {end - start:.4f} second(s)')\n\nfinished requests in 1.4278 second(s)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Asynchronous Programming with Python</span>"
    ]
  },
  {
    "objectID": "Courses/03_Asynchronous.html#thread-pool-with-asyncio",
    "href": "Courses/03_Asynchronous.html#thread-pool-with-asyncio",
    "title": "4  Asynchronous Programming with Python",
    "section": "15.4 Thread pool with asyncio",
    "text": "15.4 Thread pool with asyncio\n\nimport functools\nimport requests\nimport asyncio\nfrom concurrent.futures import ThreadPoolExecutor\n \ndef get_status_code(url: str) -&gt; int:\n    response = requests.get(url)\n    return response.status_code\n \n \n@async_timed()\nasync def main():\n    loop = asyncio.get_running_loop()\n    with ThreadPoolExecutor() as pool:\n        urls = ['https://www.example.com' for _ in range(10)]\n        tasks = [loop.run_in_executor(pool, functools.partial(get_status_code, url)) for url in urls]\n        results = await asyncio.gather(*tasks)\n        print(results)\n \nawait main()\n\nstarting &lt;function main at 0x1213b5940&gt; with args () {}\n[200, 200, 200, 200, 200, 200, 200, 200, 200, 200]\nfinished &lt;function main at 0x1213b5940&gt; in 0.8599 second(s)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Asynchronous Programming with Python</span>"
    ]
  },
  {
    "objectID": "Courses/03_Asynchronous.html#multithreading-with-numpy",
    "href": "Courses/03_Asynchronous.html#multithreading-with-numpy",
    "title": "4  Asynchronous Programming with Python",
    "section": "15.5 Multithreading with numpy",
    "text": "15.5 Multithreading with numpy\nLet’s define a big matrix on which we will compute the mean of each row.\nNow process the matrix sequentially.\n\ns = time.time()\n \nres_seq = np.mean(matrix, axis=1)\n \ne = time.time()\nprint(e - s)\n\n0.30220913887023926\n\n\nAnd then the same with multithreading (we check that the results are exactly the same).\n\nimport functools\nfrom concurrent.futures.thread import ThreadPoolExecutor\nimport asyncio\n \ndef mean_for_row(arr, row):\n    return np.mean(arr[row])\n \n@async_timed()\nasync def main():\n    loop = asyncio.get_running_loop()\n    with ThreadPoolExecutor() as pool:\n        tasks = []\n        for i in range(rows):\n            mean = functools.partial(mean_for_row, matrix, i)\n            tasks.append(loop.run_in_executor(pool, mean))\n \n        return await asyncio.gather(*tasks)\n\nres_threads = np.array(await main())\nnp.testing.assert_array_equal(res_seq, res_threads)\n\nstarting &lt;function main at 0x121a05580&gt; with args () {}\nfinished &lt;function main at 0x121a05580&gt; in 0.0163 second(s)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Asynchronous Programming with Python</span>"
    ]
  },
  {
    "objectID": "Courses/04_IPC-and-Locking.html",
    "href": "Courses/04_IPC-and-Locking.html",
    "title": "5  IPC and locking",
    "section": "",
    "text": "6 Inter-Process Communication",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>IPC and locking</span>"
    ]
  },
  {
    "objectID": "Courses/04_IPC-and-Locking.html#remainder-on-process-level-parallelization",
    "href": "Courses/04_IPC-and-Locking.html#remainder-on-process-level-parallelization",
    "title": "5  IPC and locking",
    "section": "6.1 Remainder on Process-level parallelization",
    "text": "6.1 Remainder on Process-level parallelization\n\n\n\n\n\nMulti-Processing\n\n\n\n\n\n\n\nMulti-Threading",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>IPC and locking</span>"
    ]
  },
  {
    "objectID": "Courses/04_IPC-and-Locking.html#inter-process-is-easy",
    "href": "Courses/04_IPC-and-Locking.html#inter-process-is-easy",
    "title": "5  IPC and locking",
    "section": "6.2 Inter-process is easy…",
    "text": "6.2 Inter-process is easy…\n\n\nBut if my algorithm is not “embarrassingly parallel”, what if we want to share data between processes ?\nlet’s go for Shared Memory",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>IPC and locking</span>"
    ]
  },
  {
    "objectID": "Courses/04_IPC-and-Locking.html#shared-memory-model",
    "href": "Courses/04_IPC-and-Locking.html#shared-memory-model",
    "title": "5  IPC and locking",
    "section": "6.3 Shared Memory Model",
    "text": "6.3 Shared Memory Model\n\n\nShared Memory Model",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>IPC and locking</span>"
    ]
  },
  {
    "objectID": "Courses/04_IPC-and-Locking.html#aside-memory-models",
    "href": "Courses/04_IPC-and-Locking.html#aside-memory-models",
    "title": "5  IPC and locking",
    "section": "6.4 Aside : memory models",
    "text": "6.4 Aside : memory models\n\n\n\n\n\nUMA\n\n\n\n\n\n \n\n\n\n\nNUMA\n\n\n\n\n\n\n\nThere are differents models",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>IPC and locking</span>"
    ]
  },
  {
    "objectID": "Courses/04_IPC-and-Locking.html#shared-fifos-queues",
    "href": "Courses/04_IPC-and-Locking.html#shared-fifos-queues",
    "title": "5  IPC and locking",
    "section": "6.5 Shared FIFOs : Queues",
    "text": "6.5 Shared FIFOs : Queues\nAn ubiquitous tool in multiprocessing (and distributed computing) is shared memory FIFO list, aka Queues.\nA FIFO is a :\n\nLinked list\nwith FIFO (First In First Out) semantics, with enqueue(x) et dequeue() function (or push(x)/pop())\n\n\n\n\n\n\nIn the context of multi-processing (or multi-threading) :\nShared Memory + FIFO list = Queue\nQueues are the basis of the consumer/producer model, which is widely used in concurrent and distributed applications.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>IPC and locking</span>"
    ]
  },
  {
    "objectID": "Courses/04_IPC-and-Locking.html#when-to-use-queues",
    "href": "Courses/04_IPC-and-Locking.html#when-to-use-queues",
    "title": "5  IPC and locking",
    "section": "6.6 When to use queues?",
    "text": "6.6 When to use queues?\nAn algorithm with two computations A and B where :\n\nB depends on the result of A\nA is independent of B\n\n. . .\nA could be a producer for B, and B a consumer for A.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>IPC and locking</span>"
    ]
  },
  {
    "objectID": "Courses/04_IPC-and-Locking.html#how-to-use-queues",
    "href": "Courses/04_IPC-and-Locking.html#how-to-use-queues",
    "title": "5  IPC and locking",
    "section": "6.7 How to use queues?",
    "text": "6.7 How to use queues?",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>IPC and locking</span>"
    ]
  },
  {
    "objectID": "Courses/04_IPC-and-Locking.html#producerconsumer-examples",
    "href": "Courses/04_IPC-and-Locking.html#producerconsumer-examples",
    "title": "5  IPC and locking",
    "section": "6.8 Producer/consumer, Examples",
    "text": "6.8 Producer/consumer, Examples\n\nA finds primes in a list of number, B formats and prints them every 10 numbers found.\nA fetches a bunch of images on the web, B downloads them and saves them to disk.\nA takes the orders in the restaurant, B cooks them.\n\n. . .",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>IPC and locking</span>"
    ]
  },
  {
    "objectID": "Courses/04_IPC-and-Locking.html#the-main-gotcha",
    "href": "Courses/04_IPC-and-Locking.html#the-main-gotcha",
    "title": "5  IPC and locking",
    "section": "7.1 The main gotcha",
    "text": "7.1 The main gotcha\nwhat if several processes want to write/read the same shared memory portions at the same time?\n. . .\nEnter the realm of the dreaded race condition",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>IPC and locking</span>"
    ]
  },
  {
    "objectID": "Courses/04_IPC-and-Locking.html#simple-example",
    "href": "Courses/04_IPC-and-Locking.html#simple-example",
    "title": "5  IPC and locking",
    "section": "7.2 Simple example",
    "text": "7.2 Simple example\nPrinting from several processes a string with 10 times the same char.\n\n\nfrom multiprocessing.pool import Pool\nfrom itertools import repeat\n# print \"AAAAAAAAA\", \"BBBBBBBBBBB\" etc.\ndef repeat10Cap(c): \n    print(\"\".join(repeat(chr(c+65),10))) \nwith Pool(8) as pool:\n    pool.map(repeat10Cap, range(10))\n\n\nOutput:\nAAAAAAAAAACCCCCCCCCCBBBBBBBBBBDDDDDDDDDDEEEEEEEEEE\n\n\nFFFFFFFFFFGGGGGGGGGG\nIIIIIIIIII\n\nHHHHHHHHHH\nJJJJJJJJJJ",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>IPC and locking</span>"
    ]
  },
  {
    "objectID": "Courses/04_IPC-and-Locking.html#critical-section-workflow",
    "href": "Courses/04_IPC-and-Locking.html#critical-section-workflow",
    "title": "5  IPC and locking",
    "section": "8.1 Critical section workflow",
    "text": "8.1 Critical section workflow\n\n\nThree processes with critical section",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>IPC and locking</span>"
    ]
  },
  {
    "objectID": "Courses/04_IPC-and-Locking.html#a-simple-implementation-in-python-lock",
    "href": "Courses/04_IPC-and-Locking.html#a-simple-implementation-in-python-lock",
    "title": "5  IPC and locking",
    "section": "8.2 A simple implementation in Python : Lock",
    "text": "8.2 A simple implementation in Python : Lock\n\n\nfrom multiprocessing.pool import Pool\nfrom multiprocessing import Lock\nfrom itertools import repeat\nlock = Lock()\ndef safe_repeat10Cap(c):\n    with lock: \n        # Beginning of critical section\n        print(\"\".join(repeat(chr(c+65),10)))\n        # End of critical section\nwith Pool(8) as pool:\n    pool.map(safe_repeat10Cap, range(10))\n\n\nOutput:\nAAAAAAAAAA\nBBBBBBBBBB\nCCCCCCCCCC\nDDDDDDDDDD\nEEEEEEEEEE\nFFFFFFFFFF\nGGGGGGGGGG\nHHHHHHHHHH\nIIIIIIIIII\nJJJJJJJJJJ",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>IPC and locking</span>"
    ]
  },
  {
    "objectID": "Courses/04_IPC-and-Locking.html#consistency-problems-with-fifo-example-i",
    "href": "Courses/04_IPC-and-Locking.html#consistency-problems-with-fifo-example-i",
    "title": "5  IPC and locking",
    "section": "9.1 Consistency problems with FIFO example I",
    "text": "9.1 Consistency problems with FIFO example I\nProcess A (resp. B) wants to push x (resp. y) on the list.\n\n\n\\Longrightarrow Consistency problem if they both create a new linked node to node 3.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>IPC and locking</span>"
    ]
  },
  {
    "objectID": "Courses/04_IPC-and-Locking.html#consistency-problems-with-fifo-example-2",
    "href": "Courses/04_IPC-and-Locking.html#consistency-problems-with-fifo-example-2",
    "title": "5  IPC and locking",
    "section": "9.2 Consistency problems with FIFO example 2",
    "text": "9.2 Consistency problems with FIFO example 2\nProcess A and B both want to pop the list.\n\n\n\\Longrightarrow Consistency problem if they both pop the same node.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>IPC and locking</span>"
    ]
  },
  {
    "objectID": "Courses/04_IPC-and-Locking.html#no-consistency-problems-with-fifo-example-3",
    "href": "Courses/04_IPC-and-Locking.html#no-consistency-problems-with-fifo-example-3",
    "title": "5  IPC and locking",
    "section": "9.3 (No) Consistency problems with FIFO example 3",
    "text": "9.3 (No) Consistency problems with FIFO example 3\n\n\nNo problem there.\n\n\n\n. . .\n\n\n\n\n\n\nWarning\n\n\n\n⚠ ⚠ As long the list is not empty ⚠ ⚠",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>IPC and locking</span>"
    ]
  },
  {
    "objectID": "Courses/04_IPC-and-Locking.html#deadlock-example",
    "href": "Courses/04_IPC-and-Locking.html#deadlock-example",
    "title": "5  IPC and locking",
    "section": "10.1 Deadlock example",
    "text": "10.1 Deadlock example",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>IPC and locking</span>"
    ]
  },
  {
    "objectID": "Courses/04_IPC-and-Locking.html#deadlock-serious-example",
    "href": "Courses/04_IPC-and-Locking.html#deadlock-serious-example",
    "title": "5  IPC and locking",
    "section": "10.2 Deadlock (serious) example",
    "text": "10.2 Deadlock (serious) example\n\n\nDeadlock illustration\n\n\n\n\nProcess A acquires lock L1. Process B acquires lock L2. Process A tries to acquire lock L2, but it is already held by B. Process B tries to acquire lock L1, but it is already held by A. Both processes are blocked.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>IPC and locking</span>"
    ]
  },
  {
    "objectID": "Courses/04_IPC-and-Locking.html#avoiding-deadlocks",
    "href": "Courses/04_IPC-and-Locking.html#avoiding-deadlocks",
    "title": "5  IPC and locking",
    "section": "10.3 Avoiding Deadlocks",
    "text": "10.3 Avoiding Deadlocks\nThere is several ways to avoid deadlocks. One of them is the Dijkstra’s Resource Hiearchy Solution.\n. . .\nIn the previous example, processes should try the lowest numbered locks first. Instead of B acquiring L2 first, it should tries to acquire L1 instead and L2 after.\n. . .\nThis solution isn’t universal but is pretty usable in general case.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>IPC and locking</span>"
    ]
  },
  {
    "objectID": "Courses/05_Distributed.html",
    "href": "Courses/05_Distributed.html",
    "title": "6  Distributed Computing models",
    "section": "",
    "text": "7 Map-Reduce",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Distributed Computing models</span>"
    ]
  },
  {
    "objectID": "Courses/05_Distributed.html#the-real-beating-heart-of-big-data",
    "href": "Courses/05_Distributed.html#the-real-beating-heart-of-big-data",
    "title": "6  Distributed Computing models",
    "section": "7.1 The (real) beating Heart of Big Data",
    "text": "7.1 The (real) beating Heart of Big Data\nMap\\rightarrow{}Reduce patern is the most common pattern to process data in (real) Big Data.\n. . .\nIt is heavily used by Google, Facebook, and IBM.\n. . .\nHadoop from Apache is a popular Map-Reduce framework (also called MapReduce in the Hadoop framework, not to be confused with the more general Map\\rightarrow{}Reduce Pattern).\n. . .\nHadoop is backed by a HDFS (Hadoop Distributed File System) and a YARN (Yet Another Resource Manager)\n\nHDFS is a distributed file system (a file system that is distributed across a cluster of computers)\nYARN is a resource manager (a program that manages the resources of a cluster)",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Distributed Computing models</span>"
    ]
  },
  {
    "objectID": "Courses/05_Distributed.html#split-apply-combine-pattern",
    "href": "Courses/05_Distributed.html#split-apply-combine-pattern",
    "title": "6  Distributed Computing models",
    "section": "7.2 Split-Apply-Combine pattern",
    "text": "7.2 Split-Apply-Combine pattern\n\n\n\n\nSplit:\n\nSplit the data into smaller pieces\n\nApply:\n\nProcess the data in the pieces\n\nCombine:\n\nMerge the results",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Distributed Computing models</span>"
    ]
  },
  {
    "objectID": "Courses/05_Distributed.html#map",
    "href": "Courses/05_Distributed.html#map",
    "title": "6  Distributed Computing models",
    "section": "7.3 Map",
    "text": "7.3 Map\nMap takes one pair of data with a type in one data domain, and returns a list of pairs in a different domain:\nMap(k1,v1) → list(k2,v2)\n\\Longrightarrow heavily parallelized",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Distributed Computing models</span>"
    ]
  },
  {
    "objectID": "Courses/05_Distributed.html#reduce",
    "href": "Courses/05_Distributed.html#reduce",
    "title": "6  Distributed Computing models",
    "section": "7.4 Reduce",
    "text": "7.4 Reduce\nThe values associated from the same key are combined.\nThe Reduce function is then applied in parallel to each group, which in turn produces a collection of values in the same domain:\nReduce(k2, list (v2)) → list((k3, v3))",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Distributed Computing models</span>"
    ]
  },
  {
    "objectID": "Courses/05_Distributed.html#schema",
    "href": "Courses/05_Distributed.html#schema",
    "title": "6  Distributed Computing models",
    "section": "7.5 Schema",
    "text": "7.5 Schema",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Distributed Computing models</span>"
    ]
  },
  {
    "objectID": "Courses/05_Distributed.html#canonical-example-word-count-i",
    "href": "Courses/05_Distributed.html#canonical-example-word-count-i",
    "title": "6  Distributed Computing models",
    "section": "7.6 Canonical example : Word Count, I",
    "text": "7.6 Canonical example : Word Count, I\nThe canonical MapReduce example counts the appearance of each word in a set of documents\ndef map(name, document):\n  // name: document name\n  // document: document contents (list of words)\n  for word in document:\n    emit (word, 1)\n\ndef reduce(word, partialCounts):\n  // word: a word\n  // partialCounts: a list of aggregated partial counts\n  sum = 0\n  for pc in partialCounts:\n    sum += pc\n  emit (word, sum)",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Distributed Computing models</span>"
    ]
  },
  {
    "objectID": "Courses/05_Distributed.html#canonical-example-word-count-ii",
    "href": "Courses/05_Distributed.html#canonical-example-word-count-ii",
    "title": "6  Distributed Computing models",
    "section": "7.7 Canonical example : Word Count, II",
    "text": "7.7 Canonical example : Word Count, II",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Distributed Computing models</span>"
    ]
  },
  {
    "objectID": "Courses/05_Distributed.html#spark-spiritual-son-of-mapreduce",
    "href": "Courses/05_Distributed.html#spark-spiritual-son-of-mapreduce",
    "title": "6  Distributed Computing models",
    "section": "7.8 Spark, spiritual son of MapReduce",
    "text": "7.8 Spark, spiritual son of MapReduce\nSpark is widely used for machine learning on scalable data sets (faster than MapReduce by an order of magnitude).\n. . .\nSpark is largely inspired by the MapReduce pattern but extends it by using a distributed graph rather than a “linear” data flow like Map\\rightarrow{}Reduce.\n\\Longrightarrow Complex disbributed computing.\n. . .\nSpark emphasizes ease of use of the cluster ressources in a simple and functional way",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Distributed Computing models</span>"
    ]
  },
  {
    "objectID": "Courses/05_Distributed.html#spark-code-example-word-count",
    "href": "Courses/05_Distributed.html#spark-code-example-word-count",
    "title": "6  Distributed Computing models",
    "section": "7.9 Spark, code example : Word Count",
    "text": "7.9 Spark, code example : Word Count\ntext_file = sc.textFile(\"hdfs://...\")\ncounts = text_file.flatMap(lambda line: line.split(\" \")) \\\n             .map(lambda word: (word, 1)) \\\n             .reduceByKey(lambda a, b: a + b)\ncounts.saveAsTextFile(\"hdfs://...\")",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Distributed Computing models</span>"
    ]
  },
  {
    "objectID": "Courses/05_Distributed.html#spark-another-example-machine-learning",
    "href": "Courses/05_Distributed.html#spark-another-example-machine-learning",
    "title": "6  Distributed Computing models",
    "section": "7.10 Spark, another example : machine learning",
    "text": "7.10 Spark, another example : machine learning\n# Every record of this DataFrame contains the label and\n# features represented by a vector.\ndf = sqlContext.createDataFrame(data, [\"label\", \"features\"])\n\n# Set parameters for the algorithm.\n# Here, we limit the number of iterations to 10.\nlr = LogisticRegression(maxIter=10)\n\n# Fit the model to the data.\nmodel = lr.fit(df)\n\n# Given a dataset, predict each point's label, \n# and show the results.\nmodel.transform(df).show()",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Distributed Computing models</span>"
    ]
  },
  {
    "objectID": "Courses/05_Distributed.html#schema-1",
    "href": "Courses/05_Distributed.html#schema-1",
    "title": "6  Distributed Computing models",
    "section": "8.1 Schema",
    "text": "8.1 Schema",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Distributed Computing models</span>"
    ]
  },
  {
    "objectID": "Courses/05_Distributed.html#main-message-passing-functions",
    "href": "Courses/05_Distributed.html#main-message-passing-functions",
    "title": "6  Distributed Computing models",
    "section": "8.2 Main message-passing functions",
    "text": "8.2 Main message-passing functions\n\n\nScatter\n\npartition the data into smaller pieces and send them to the different processes\n\nGather\n\ncollect the data from the different processes and merge them.\n\nBroadcast\n\nSend the same data to all the processes.\n\nReduce\n\nMerge the data from all the processes and produce a single result.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Distributed Computing models</span>"
    ]
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "7  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Summary</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Fowler, M. 2022. Python Concurrency with Asyncio. Manning. https://www.manning.com/books/python-concurrency-with-asyncio.\n\n\nRobey, R., and Y. Zamora. 2021. Parallel and High Performance\nComputing. Manning. https://www.manning.com/books/parallel-and-high-performance-computing.\n\n\nVaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion\nJones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017.\n“Attention Is All You Need.” Advances in Neural\nInformation Processing Systems 30.",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "applications.html",
    "href": "applications.html",
    "title": "Appendix A — Applications",
    "section": "",
    "text": "Original (In Percent Format)\nOnline Html (Corrected)\nNotebook (Corrected)\n\n\n\n\nPrompt engineering exercises\nSolution\nNotebook\n\n\nAI Agent\nSolution\nNotebook\n\n\nNumpy Workout\n\n\n\n\nDecorators Tutorial\nSolution\nNotebook\n\n\nA tutorial on Python generators\nSolution\nNotebook\n\n\nMultiprocessing in Python 3\nSolution\nNotebook\n\n\nScaling App with multiprocessing\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Applications</span>"
    ]
  },
  {
    "objectID": "slides.html",
    "href": "slides.html",
    "title": "Appendix B — Slides in reveal.js",
    "section": "",
    "text": "Code Assistants\nNumpy Workout\nIntroduction to parallel computing\nAsynchronous Programming with Python\nIPC and locking\nDistributed Computing models\n\nNo matching items",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Slides in reveal.js</span>"
    ]
  }
]